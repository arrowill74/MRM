{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 4876)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_4876.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [[2 1 0 ... 1 0 0]\n",
      " [4 8 4 ... 0 0 0]\n",
      " [2 2 2 ... 1 0 0]\n",
      " ...\n",
      " [5 3 0 ... 1 1 0]\n",
      " [2 2 0 ... 0 1 0]\n",
      " [3 2 0 ... 1 1 0]]\n",
      "After: [[0.22222222 0.11111111 0.         ... 0.11111111 0.         0.        ]\n",
      " [0.44444444 0.88888889 0.44444444 ... 0.         0.         0.        ]\n",
      " [0.4        0.4        0.4        ... 0.2        0.         0.        ]\n",
      " ...\n",
      " [0.26315789 0.15789474 0.         ... 0.05263158 0.05263158 0.        ]\n",
      " [0.28571429 0.28571429 0.         ... 0.         0.14285714 0.        ]\n",
      " [0.33333333 0.22222222 0.         ... 0.11111111 0.11111111 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Before:', usr_genre)\n",
    "print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "\n",
    "print(usr_nb, movie_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 16\n"
     ]
    }
   ],
   "source": [
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "usr_idx = [i for i in range(len(usr_following))]\n",
    "print(len(usr_idx))\n",
    "\n",
    "test_idx = random.sample(usr_idx, usr_test_amount)\n",
    "print(len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "train_t = [0] * usr_nb\n",
    "train_f = [0] * usr_nb\n",
    "# Testing\n",
    "test_t = [0] * usr_test_amount\n",
    "test_f = [0] * usr_test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(usr_following)):\n",
    "    \n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        \n",
    "        for j in range(movie_nb):\n",
    "            \n",
    "            if usr_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        \n",
    "        # random choose 2 true and 8 false for test \n",
    "        t_for_test = random.sample(temp_t, 2)\n",
    "        f_for_test  = random.sample(temp_f, 8)\n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1582\n",
      "The length of train_f: 1582\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "# train_t[i] 代表的是user i positive feedback\n",
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'MRM_ALL_Embedding100'\n",
    "LATENT_FOLDER = './latent_factor/MRM_ALL/Embedding100/'\n",
    "newPath(LATENT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 4876 100\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 100\n",
    "\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None,ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [usr_nb, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [latent_dim,latent_dim], \n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [movie_nb, latent_dim, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [latent_dim, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [latent_dim, ft_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "    ########## Error part, how to get auxisize dynamically\n",
    "    ####aux_size= tf.get_variable(name='aux_size', initializer=l_id.get_shape().as_list()[-1])\n",
    "    \n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.00001,0.000001,seed=10))\n",
    "    \n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "w1 = tf.nn.embedding_lookup(W1, user) #(1*k)\n",
    "wu = Wu\n",
    "#wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user)) #(k*k)\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, i)) #(k*k)\n",
    "wa = Wa\n",
    "#wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user)) #(k*k)\n",
    "wv = Wv\n",
    "#wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user)) #(k,l)\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-15-e975e9415cb9>:76: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,ft_dim)\n",
    "    \n",
    "    a_list = tf.concat([a_list,[(tf.matmul( w1, tf.nn.relu( tf.matmul(wu, u, transpose_b=True) +\n",
    "        tf.matmul(wy, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wa, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wv, xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q,  a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_soft = tf.nn.softmax(a_list)\n",
    "\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    #aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "#tf.print('aux attention:',aux_np)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "norm_par = [tf.reduce_sum(tf.multiply(u, u)),tf.reduce_sum(tf.multiply(vi, vi)),tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "           tf.reduce_sum(tf.multiply(w1, w1)),tf.reduce_sum(tf.multiply(wu, wu)),tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "           tf.reduce_sum(tf.multiply(wa, wa)),tf.reduce_sum(tf.multiply(wv,wv)),tf.reduce_sum(tf.multiply(beta,beta))]\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "  \n",
    "            0.0001 * tf.reduce_sum(tf.multiply(w1, w1)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "            \n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            \n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: Fri Mar  6 04:33:28 2020\n",
      "Iteration: 0\n",
      "total_loss          [[0.11568376]]\n",
      "train_auc:          0.9612373628272703\n",
      "\tCurrent time: Fri Mar  6 05:15:07 2020\n",
      "==================================================\n",
      "Iteration: 1\n",
      "total_loss          [[0.0393897]]\n",
      "train_auc:          0.9868184567527867\n",
      "\tCurrent time: Fri Mar  6 05:56:42 2020\n",
      "==================================================\n",
      "Iteration: 2\n",
      "total_loss          [[0.01651899]]\n",
      "train_auc:          0.9948414412857514\n",
      "\tCurrent time: Fri Mar  6 06:38:15 2020\n",
      "==================================================\n",
      "Iteration: 3\n",
      "total_loss          [[0.00886174]]\n",
      "train_auc:          0.9973991186382096\n",
      "\tCurrent time: Fri Mar  6 07:19:49 2020\n",
      "==================================================\n",
      "Iteration: 4\n",
      "total_loss          [[0.00596072]]\n",
      "train_auc:          0.9983388058411821\n",
      "\tCurrent time: Fri Mar  6 08:01:29 2020\n",
      "==================================================\n",
      "Total cost time: 12480.271223545074\n",
      "End time: Fri Mar  6 08:01:29 2020\n"
     ]
    }
   ],
   "source": [
    "print('Start time:', time.ctime())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_acc_list = []\n",
    "t0 = time.time()\n",
    "\n",
    "#use_true=init_list_of_objects(136)\n",
    "#use_test=init_list_of_objects(136)\n",
    "\n",
    "#train_pair_t=[] #positive feedback\n",
    "#train_pair_f=[] #negative feedback\n",
    "train_yes_id=[]\n",
    "\n",
    "for q in range(5):\n",
    "    print('Iteration:',q)\n",
    "    train_auc = 0\n",
    "    total_loss = 0\n",
    "    xuij_auc = 0\n",
    "    length = 0\n",
    "    \n",
    "    for z in range(usr_nb):\n",
    "        \"\"\"\n",
    "        yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "        yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "        r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "        \"\"\"\n",
    "        yes = []\n",
    "        yesr = []\n",
    "        \n",
    "        sample = random.sample(train_t[z],len(train_t[z])) #隨機選3個sample true's YouTuber\n",
    "        train_yes_id.append(sample) #sample全部丟進去\n",
    "        \n",
    "        #sample=random.sample(train_t[z]+train_f[z],len(train_t[z])+len(train_f[z]))\n",
    "        \n",
    "        #change\n",
    "        r_3 = np.zeros(len(sample)) \n",
    "        alpha_history = []\n",
    "        a_list_history = []\n",
    "        U_history = []\n",
    "        Y_history = []\n",
    "        \n",
    "        #print(len(sample))\n",
    "        #check if all YouTuber are in train_t or train_f\n",
    "        #if len(train_t[z])+len(train_f[z]) != 88:\n",
    "            #print(z,len(train_t[z])+len(train_f[z]))\n",
    "         \n",
    "        for b in range(len(sample)):\n",
    "            yes.append(all_npy[sample[b]])\n",
    "            yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "            #print('YouTuber_category ', YouTuber_category[sample[k]])\n",
    "            #print('User_category ',user_category_norm[z])\n",
    "        #print(len(yes))\n",
    "        \n",
    "        for b in range(len(yesr)):\n",
    "            r_3[b]=max(yesr[b])\n",
    "        #print('r_3:',r_3)\n",
    "        \n",
    "        yes = np.array(yes)\n",
    "        #print('user shape should be ',np.array([z]).shape)\n",
    "        #print('xf shape should be ',yes.shape)\n",
    "        #print('r shape should be ',np.array(r_3).shape)\n",
    "        #print('l_id shape should be ',np.array(sample).shape)\n",
    "        \n",
    "        #not_used_list = list(set(train_t[z]).difference(set(sample)))\n",
    "        \n",
    "        # positive \n",
    "        train_t_sample = random.sample(train_t[z],len(train_t[z]))\n",
    "        #print('number of positive feedback', len(train_t[z]))\n",
    "        # negative\n",
    "        train_f_sample = random.sample(train_f[z],20)\n",
    "        \n",
    "        for ta in train_t_sample:\n",
    "            #print(ta,'--> positive feedback')\n",
    "            \n",
    "            pos = sample.index(ta)\n",
    "            #new_sample = np.delete(sample,[pos])\n",
    "            #new_yes = np.delete(yes,[pos],axis=0)\n",
    "            #new_r_3 = np.delete(r_3,[pos])\n",
    "            new_sample = sample\n",
    "            new_yes = yes\n",
    "            new_r_3 = r_3\n",
    "            #print(len(yes),len(new_yes))\n",
    "            #print(yes)\n",
    "            #print(new_yes)\n",
    "            \n",
    "            #ta=random.choice(train_t[z]) #ta is true positve photo\n",
    "            #train_pair_t.append(ta)\n",
    "            image_1=np.expand_dims(all_npy[ta],0) #(1,2048)\n",
    "            #print('Image_1 shape ',image_1.shape)\n",
    "            #train_f_sample = random.sample(train_f[z],20)\n",
    "            #print('True:',train_t_sample,'Now:',ta)\n",
    "            #print('False:',train_f_sample)\n",
    "            \n",
    "            for b in train_f_sample:\n",
    "                #print('likes:',ta,';Not likes:',b)\n",
    "                #b=random.choice(train_f[z])  #b is no feedback photo\n",
    "                #train_pair_f.append(b)\n",
    "                image_2=np.expand_dims(all_npy[b],0) #(1,2048)\n",
    "                #print('Image_2 shape',image_2.shape)\n",
    "            \n",
    "                #use_test[z].append(b)\n",
    "                _embedding,_a_list,r3,_auc, _loss,_=sess.run([embedding,a_list,a_list_soft,auc,loss,train_op], feed_dict={user: [z],\n",
    "                                        i: [ta], j: [b], xf: new_yes , l_id:new_sample, l_id_len:[len(new_sample)],r:new_r_3,\n",
    "                                        image_i:image_1,image_j:image_2})\n",
    "                \n",
    "                #print(XUIJ)\n",
    "                #print('loss=',_loss)\n",
    "                #print('auc=',_auc)\n",
    "                \n",
    "                #print('after softmax:',r3)\n",
    "                #print('before softmax:',_a_list)\n",
    "                #print('embedding:',_embedding)\n",
    "                #print('---------------------------------------------------')\n",
    "                a_list_history.append(_a_list)\n",
    "                alpha_history.append(r3)\n",
    "                train_auc += _auc\n",
    "                total_loss += _loss\n",
    "                length += 1\n",
    "            #now1+=1\n",
    "        \n",
    "        np.save(LATENT_FOLDER + str(q) + '_' + str(z),_embedding)\n",
    "    \n",
    "    #print('mine:',xuij_auc/136)   \n",
    "    #print('a_list_soft:',r3)\n",
    "    print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "    print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "    \n",
    "    loss_acc_list.append([total_loss/length, train_auc/length, time.time()-t0])\n",
    "    \n",
    "    print('\\tCurrent time:', time.ctime())\n",
    "    print('==================================================')\n",
    "    \n",
    "print('Total cost time:',time.time()-t0)\n",
    "\n",
    "print('End time:', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss= [[0.11568376]]\n",
      "acc= 0.9612373628272703\n",
      "==================================================\n",
      "Iteration: 1\n",
      "loss= [[0.0393897]]\n",
      "acc= 0.9868184567527867\n",
      "==================================================\n",
      "Iteration: 2\n",
      "loss= [[0.01651899]]\n",
      "acc= 0.9948414412857514\n",
      "==================================================\n",
      "Iteration: 3\n",
      "loss= [[0.00886174]]\n",
      "acc= 0.9973991186382096\n",
      "==================================================\n",
      "Iteration: 4\n",
      "loss= [[0.00596072]]\n",
      "acc= 0.9983388058411821\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_acc_list)):\n",
    "    print('Iteration:',i)\n",
    "    print('loss=',loss_acc_list[i][0])\n",
    "    print('acc=',loss_acc_list[i][1])\n",
    "#     print('time=',loss_acc_list[i][2])\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U, Y, A, A1, Au, Ay, Aa, Av, E, B = sess.run([user_latent, item_latent, aux_item, \n",
    "                                              W1, Wu, Wy, Wa, Wv, embedding, Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent shape:  (1582, 128)\n",
      "photo latent shape:  (165, 128)\n",
      "Auxilary latent shape:  (165, 128)\n",
      "W1 weight shape:  (1582, 128)\n",
      "Wu weight shape: (128, 128)\n",
      "Wy weight shape: (165, 128, 128)\n",
      "Wa weight shape: (128, 128)\n",
      "Wv weight shape: (128, 4876)\n",
      "Embedding shape: (100, 4876)\n",
      "Beta shape: (1582, 100)\n"
     ]
    }
   ],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('W1 weight shape: ',A1.shape)\n",
    "print('Wu weight shape:',Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./weight/' + SAVE_NAME + '.npz', \n",
    "         U=U, Y=Y, A=A, A1=A1, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, E=E, B=B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1413\n",
      "alpha:         [ 7.82045189e-22  7.03733385e-23 -2.86553268e-22  2.32686175e-46\n",
      "  8.31971643e-22  1.22593311e-25  4.54947579e-47  1.18190723e-31\n",
      "  2.71753468e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "1 918\n",
      "alpha:         [ 1.23194919e-26 -4.48767498e-28  4.43010059e-27  2.86874598e-27\n",
      "  2.45562479e-27 -4.52063099e-26  1.05924145e-51  7.67051600e-26\n",
      " -8.79388981e-27  2.85879181e-26 -1.18760099e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "2 525\n",
      "alpha:         [9.19430248e-23 3.87562453e-23 1.96580257e-25 3.02430756e-22\n",
      " 6.39647471e-24 2.13138940e-22 6.78877036e-23 2.72840704e-22\n",
      " 3.25357774e-31]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "3 262\n",
      "alpha:         [-4.28877147e-22  1.11924266e-21 -1.01832878e-21 -9.91259749e-23\n",
      "  1.22998901e-27  3.48911504e-22  5.29579231e-46 -1.18884416e-22\n",
      " -3.62556759e-47]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "4 1390\n",
      "alpha:         [-2.08255037e-26 -1.86051905e-21  1.25084661e-21  1.36461341e-22\n",
      "  2.51506329e-22 -1.10206140e-21  2.12581398e-22 -2.75019600e-22\n",
      "  5.65679008e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "5 340\n",
      "alpha:         [1.63541228e-26 6.14334956e-27 1.71388610e-26 4.63605728e-26\n",
      " 1.04412574e-30 1.66686336e-26 1.49214766e-26 5.16871722e-26\n",
      " 5.51405234e-27 7.85196215e-27 7.66925955e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "6 309\n",
      "alpha:         [-5.22599070e-26 -4.63406045e-51 -2.37822284e-26 -2.78598683e-26\n",
      "  2.98135631e-27  4.66048482e-36 -2.17020160e-26 -3.30874254e-27\n",
      " -1.29401597e-26 -1.43260703e-26 -2.33397335e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "7 544\n",
      "alpha:         [-3.62342133e-20 -6.93600609e-20 -2.16583479e-20  2.20330692e-20\n",
      " -6.71055234e-20 -1.11401213e-43  3.31071000e-21 -5.24165943e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "8 218\n",
      "alpha:         [-5.02592316e-35  3.76357647e-35 -1.60197175e-35  1.50711020e-35\n",
      " -1.59026998e-35 -5.01476690e-35  8.85739063e-36 -1.00210098e-35\n",
      "  6.74038879e-35  1.53231722e-36  9.71949634e-36 -8.11152052e-60\n",
      "  1.42573266e-35 -2.44569828e-35 -4.05773964e-37  9.21408279e-35\n",
      "  3.34476326e-35 -5.80012470e-39  2.97056300e-36 -1.67367246e-35\n",
      "  3.08754159e-35  1.77323220e-35  1.91520837e-35 -2.18822735e-35\n",
      " -1.32922516e-35 -6.52511695e-59 -7.13299999e-36  2.53001106e-35\n",
      " -5.69348122e-59  1.15570242e-36 -2.02160837e-36 -4.22004853e-36\n",
      "  7.24037248e-35 -4.61756265e-35 -8.16416796e-47 -9.12908509e-36\n",
      "  7.94076828e-35 -4.13665930e-41  1.65372125e-35 -1.31935856e-35\n",
      " -6.90828864e-37]\n",
      "softmax alpha: [0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024]\n",
      "==================================================\n",
      "9 697\n",
      "alpha:         [-1.75716944e-35 -2.63558079e-35 -1.91204031e-35 -3.75282679e-36\n",
      " -4.91603005e-35  2.50195931e-36  1.25826513e-35  2.28147066e-35\n",
      " -6.13411362e-35 -3.29542937e-35 -3.80035866e-35 -6.52911953e-35\n",
      "  4.54146020e-35 -2.77781049e-42 -8.80220577e-36  1.37046111e-35\n",
      " -5.76339414e-36 -1.07904951e-35 -7.63317943e-35 -2.86336358e-59\n",
      "  5.09778836e-37  7.74541430e-35  1.48342718e-34 -1.36918847e-59\n",
      " -2.34100065e-35  1.09827277e-35 -2.90251264e-36]\n",
      "softmax alpha: [0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704]\n",
      "==================================================\n",
      "10 1155\n",
      "alpha:         [ 1.67179369e-33  3.74572156e-33 -1.41790965e-34  1.88880178e-58\n",
      "  4.62829227e-43  4.89317796e-59 -1.73568600e-33 -3.80049215e-34\n",
      " -8.39791897e-35 -5.69025127e-34  1.69920073e-57  1.46281673e-33\n",
      "  7.52560952e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "11 1092\n",
      "alpha:         [ 2.08876242e-22 -1.84488762e-23  7.40063999e-24  2.29227071e-22\n",
      "  4.13060237e-46  1.99813476e-21  2.10612564e-22  3.29406067e-23\n",
      "  3.79188165e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "12 602\n",
      "alpha:         [-2.03029119e-35 -2.15392301e-35  4.47550423e-61 -1.53984030e-34\n",
      " -4.94664522e-35 -4.08627814e-36  5.07107889e-36 -5.83010027e-35\n",
      "  9.84982911e-60 -6.49988281e-36 -3.11344175e-36 -1.05236639e-35\n",
      " -1.29142546e-34 -3.88116733e-35 -5.00940853e-36 -2.52416679e-35\n",
      " -4.67233014e-36 -1.44564359e-34 -1.30166059e-35]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "13 86\n",
      "alpha:         [-8.29161914e-21  5.26418079e-20 -5.72728860e-20 -3.01313699e-19\n",
      " -2.57686513e-19 -3.74443257e-20 -1.14575631e-19  2.57235553e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "14 671\n",
      "alpha:         [ 1.47166506e-45  1.61438266e-21  7.42490783e-22  2.80143759e-20\n",
      " -2.08321459e-20  6.06956631e-20 -2.01380411e-44 -2.63531690e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "15 88\n",
      "alpha:         [ 2.47192419e-35 -1.20107229e-35  8.27135962e-35  3.05801285e-35\n",
      "  3.47410186e-35  6.50121119e-35 -3.56808949e-35  7.89570686e-35\n",
      "  6.17744299e-36  1.40991523e-34  2.37959240e-35 -5.24957033e-36\n",
      "  6.43898040e-35  1.27511411e-59 -3.49881899e-36  1.33921555e-36]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "16 1534\n",
      "alpha:         [ 3.11128869e-59  1.56706477e-34 -1.88658208e-35  3.67192832e-34\n",
      "  3.96103010e-36 -1.41861365e-35  6.76364827e-35  4.17358173e-36\n",
      "  5.51095347e-35  3.72197885e-34  9.99341521e-36  2.25974892e-34\n",
      "  8.53496980e-35  4.15704400e-36  6.18410306e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "17 1317\n",
      "alpha:         [ 2.71654180e-35  5.47868200e-37 -5.11713357e-44 -1.37391624e-39\n",
      " -1.81832076e-35 -2.23082970e-35  2.58051754e-36  5.51146772e-35\n",
      " -3.44686883e-35  1.23505881e-35 -2.12713128e-35  9.77753764e-35\n",
      "  5.11280923e-36  3.99857417e-35  3.95910919e-36  1.57424185e-35\n",
      " -5.46931063e-41 -7.35696688e-35  5.41244446e-36  2.96301580e-36\n",
      " -2.31560833e-59 -2.03796528e-35]\n",
      "softmax alpha: [0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455]\n",
      "==================================================\n",
      "18 1442\n",
      "alpha:         [ 9.84851405e-20  2.47799673e-20 -3.22711562e-19  7.04237723e-21\n",
      "  8.12908631e-20  5.51355478e-20 -7.72889913e-23  3.47695897e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "19 185\n",
      "alpha:         [-3.84699248e-20 -3.40907172e-19 -3.69129229e-20 -1.13649812e-43\n",
      " -4.07347223e-21 -4.44130301e-21 -3.55007730e-20 -1.05557354e-43]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "20 51\n",
      "alpha:         [ 6.27350654e-25 -9.63875629e-25 -7.74816280e-26  1.95828251e-24\n",
      "  4.91000073e-24  3.89199007e-24  3.06108856e-26  4.82301726e-24\n",
      "  3.26712006e-33  1.68402181e-23]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "21 1051\n",
      "alpha:         [ 3.07879607e-46 -1.08330331e-34 -3.31833374e-35  5.44550930e-35\n",
      " -6.15344713e-35  2.34748195e-35 -1.14834484e-34  4.78318687e-37\n",
      " -2.60235158e-34 -4.57580963e-35 -4.39969031e-35 -9.02141892e-35\n",
      "  1.08425473e-34  3.18154014e-35 -2.15230943e-34]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "22 1065\n",
      "alpha:         [2.35571835e-26 7.37157163e-23 6.21273955e-22 4.00719087e-22\n",
      " 2.66302792e-21 3.75661498e-22 8.21400920e-23 3.29850673e-23\n",
      " 7.94585900e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "23 1321\n",
      "alpha:         [ 3.36754631e-34  4.03560375e-34  8.65845381e-33  2.10958265e-33\n",
      "  1.49596379e-33  4.43823209e-34  3.98112711e-57  6.43904845e-33\n",
      "  4.35351823e-33  1.48599071e-33  1.68475105e-33  1.30849724e-33\n",
      "  3.55942982e-33 -7.35277897e-58]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "24 188\n",
      "alpha:         [-3.96314156e-30 -9.47270371e-30 -3.81923862e-54  6.54071730e-29\n",
      "  4.15999554e-29  1.95906705e-29 -3.23827162e-29  4.52002796e-29\n",
      "  2.95117866e-31  6.05241928e-30 -2.65489519e-29 -1.00674690e-28]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "25 1479\n",
      "alpha:         [ 7.74139215e-25  6.43528719e-24 -1.08237204e-24  1.08415284e-26\n",
      " -2.86823744e-25  5.18662224e-24  2.88289536e-24  2.46122827e-24\n",
      "  2.20923817e-24  7.54984297e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "26 333\n",
      "alpha:         [-4.78613342e-22  2.43936936e-22  6.75113259e-23 -1.38568412e-22\n",
      "  1.13519189e-21  2.64004574e-22  3.37307001e-22  1.13078020e-22\n",
      " -4.57674832e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "27 1357\n",
      "alpha:         [ 5.44454040e-46 -1.29768568e-22 -3.62975945e-27 -2.78659499e-22\n",
      "  1.24301674e-22 -4.15800933e-23 -5.95165625e-22 -2.37944684e-22\n",
      "  3.69081852e-25]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "28 1297\n",
      "alpha:         [ 2.42477200e-20  2.08957409e-20 -3.49137953e-20 -2.66999648e-20\n",
      " -3.68119564e-20  2.08686407e-19 -2.70491109e-20  3.03692575e-44]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "29 927\n",
      "alpha:         [ 4.80541937e-35 -5.88011401e-34 -5.72066086e-43 -4.82723164e-34\n",
      "  9.70817375e-59  1.32939984e-35 -2.67069668e-40  7.69928349e-36\n",
      "  1.21624372e-33 -1.79240918e-33 -7.55229718e-58  1.26199188e-35\n",
      " -9.63178074e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "30 667\n",
      "alpha:         [ 4.63298818e-22 -1.72292493e-22 -3.00437537e-46 -3.82059903e-47\n",
      " -8.46303731e-23 -4.40507458e-46 -1.83438867e-22  3.40014719e-22\n",
      " -8.33723572e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "31 186\n",
      "alpha:         [-4.99632015e-24 -4.69256770e-26  2.87838083e-24  1.21964853e-24\n",
      " -1.20313626e-23  7.40396302e-24  1.41680836e-32  1.12071508e-24\n",
      "  5.06572911e-25  8.08968843e-25]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "32 1019\n",
      "alpha:         [ 1.62048764e-25  1.12630241e-23 -1.46893026e-23  3.01774961e-24\n",
      " -1.89858261e-25 -7.11021441e-29 -8.38837952e-25 -3.84252695e-25\n",
      " -1.81844940e-24  3.02379800e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "33 1230\n",
      "alpha:         [ 1.88745511e-24 -2.45801173e-20  8.80666867e-21 -1.74767077e-21\n",
      "  2.96653275e-22  1.11872058e-20 -5.12635421e-22 -5.07160126e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "34 1421\n",
      "alpha:         [-4.12752210e-37 -1.58817483e-35 -2.94185213e-35  2.37809802e-35\n",
      " -4.48663095e-60  8.72933743e-36  1.98427909e-35 -7.29777616e-60\n",
      "  1.32279982e-35 -1.13423509e-36  8.51117934e-37 -3.69799253e-37\n",
      "  3.20504598e-35 -3.95931000e-59  2.09086156e-35 -1.85619215e-35\n",
      "  1.80376004e-35 -3.12965013e-35  7.25677945e-35 -2.20199972e-37]\n",
      "softmax alpha: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "==================================================\n",
      "35 717\n",
      "alpha:         [ 7.34518897e-21 -2.98042140e-20  5.38708674e-20  4.40878300e-20\n",
      "  1.37335329e-20 -1.48011203e-21 -1.36525125e-20 -2.33868582e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "36 44\n",
      "alpha:         [-1.85035839e-44 -8.65756642e-25 -5.62842151e-20 -6.94651788e-20\n",
      "  8.79948472e-21  5.32982213e-20  1.11115190e-19  1.05934966e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "37 302\n",
      "alpha:         [-1.89468051e-24  4.16023991e-24 -9.49689510e-24 -2.41596879e-24\n",
      " -3.96348851e-24 -2.08709843e-24  1.29061888e-24 -9.32904086e-24\n",
      "  6.69859886e-51 -6.38685756e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "38 519\n",
      "alpha:         [-7.96638462e-20 -8.98842621e-20 -2.69339298e-30 -2.32806786e-20\n",
      " -6.11866752e-20 -9.14943017e-20 -1.30460706e-19 -2.80892912e-44]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "39 358\n",
      "alpha:         [-6.90199249e-36 -1.15208276e-35 -3.91712980e-59 -7.72993969e-35\n",
      " -1.38030891e-35  1.84300040e-36 -4.02111299e-40 -2.87235073e-35\n",
      " -7.14637163e-35 -1.18693219e-36  3.26898165e-35 -1.45687884e-34\n",
      "  7.26905214e-35 -1.08184658e-36 -1.15021140e-35 -4.36275222e-35]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "40 774\n",
      "alpha:         [-1.90470216e-59 -7.97720557e-35  6.60901196e-35 -4.75561177e-35\n",
      " -4.40983737e-35 -2.40879677e-58 -1.55212481e-34 -2.34013092e-35\n",
      " -1.08753052e-34 -6.23402818e-35  1.15323032e-34 -1.31329215e-34\n",
      " -4.35263805e-36 -3.99279834e-59 -6.68973903e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "41 706\n",
      "alpha:         [ 5.03104238e-34  2.59087455e-34  2.81034211e-35  1.91652135e-34\n",
      "  1.88095187e-34  3.09421534e-35  2.42568384e-35 -1.57695884e-39\n",
      "  2.42771935e-35  1.80119023e-34  5.40857120e-34  5.62247211e-44\n",
      "  5.30691464e-58  9.98016182e-35 -7.46193424e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "42 7\n",
      "alpha:         [ 2.25391158e-22 -1.98548162e-23 -2.01578774e-23 -1.76959708e-21\n",
      " -4.14742836e-25 -2.01108480e-21 -1.07102600e-21  2.16966451e-22\n",
      " -1.88574778e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "43 1458\n",
      "alpha:         [ 7.87204409e-36  3.53442332e-59 -3.23874457e-36 -2.48805593e-35\n",
      "  8.72491458e-35 -1.32251954e-35  3.27198228e-59 -1.37626241e-34\n",
      " -2.41610429e-35 -5.54580009e-35 -3.31591293e-35 -7.00572162e-36\n",
      " -4.76238434e-35 -9.43281237e-35 -1.23497305e-39 -7.14544460e-37\n",
      " -9.09710915e-35 -4.49293224e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "44 672\n",
      "alpha:         [-9.27539591e-51  3.28137620e-26  1.14946220e-26 -1.13508928e-50\n",
      " -9.36610201e-51 -4.72915920e-27 -5.77217112e-27  1.12582416e-27\n",
      " -5.53656864e-27 -1.32362162e-27 -1.92435862e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "45 1453\n",
      "alpha:         [ 2.09214018e-20  9.53790775e-20 -2.04040635e-20  1.90534876e-20\n",
      "  3.41140726e-20  1.58247307e-20  1.33302392e-19 -3.50789995e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "46 87\n",
      "alpha:         [-1.91931747e-35 -7.44646063e-35  4.27982808e-35  4.27900956e-35\n",
      " -3.31941436e-39 -7.82471395e-36  4.69546964e-59  6.54749750e-35\n",
      "  1.09192990e-35  1.52842136e-36  3.62660016e-35 -2.14511827e-35\n",
      " -4.62901134e-35 -1.24764174e-34 -6.96873306e-35  3.24422176e-35\n",
      " -7.38382570e-35  1.15696911e-35  4.32947423e-35  2.75636782e-35]\n",
      "softmax alpha: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "==================================================\n",
      "47 1427\n",
      "alpha:         [8.33188568e-35 1.74558909e-36 1.66457778e-35 4.57737896e-35\n",
      " 6.19537201e-35 6.67461399e-35 2.08887676e-35 5.40299468e-61\n",
      " 4.73075780e-37 5.41866773e-36 1.11946563e-35 3.83358362e-35\n",
      " 3.10229008e-35 8.88619096e-35 2.40158883e-44 2.78900603e-35]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "48 190\n",
      "alpha:         [ 5.17667238e-26  2.76605957e-24 -1.81774437e-25  1.36413900e-25\n",
      " -4.22844844e-49  1.98362150e-24  7.22968863e-25  5.26996890e-26\n",
      "  5.22556234e-25  1.26758856e-23]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "49 1411\n",
      "alpha:         [-5.04944709e-35 -1.27828366e-34 -8.16037787e-35 -5.05304624e-35\n",
      " -3.28976907e-35 -1.60935307e-59 -1.34466205e-35 -3.16742679e-35\n",
      " -1.83596348e-34 -2.46436880e-35 -1.36059453e-36 -6.97413304e-61\n",
      " -6.25588030e-35 -1.16306300e-36 -1.44045464e-35 -7.52650938e-35\n",
      " -1.25551571e-35 -5.58587007e-36 -1.62167949e-35 -7.56189230e-36\n",
      " -1.42219728e-34]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "50 828\n",
      "alpha:         [ 4.06355547e-35  1.29391334e-35  3.93899847e-35  2.60921577e-35\n",
      " -1.86536062e-35  1.17738510e-34  6.27026397e-35 -2.66558543e-44\n",
      " -5.37053299e-36 -4.27432804e-35  4.73092504e-36 -1.53690856e-59\n",
      "  2.91173742e-35 -1.20120327e-36 -2.75414993e-35  7.00233353e-36\n",
      "  7.19973633e-36  1.36599340e-35  2.40037282e-38  5.96789571e-35\n",
      " -9.88969786e-37]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "51 1274\n",
      "alpha:         [-2.24128964e-21 -5.08144898e-20 -2.09661306e-20 -7.22027999e-25\n",
      " -5.64789401e-20 -4.16719166e-19 -6.40357884e-20 -5.60649227e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "52 935\n",
      "alpha:         [-7.77715099e-23 -1.24555207e-46  7.96584494e-23  2.89582476e-22\n",
      "  1.83062992e-22  2.57135771e-22 -2.40242347e-25  5.88794766e-22\n",
      "  7.08548959e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "53 1307\n",
      "alpha:         [ 3.05222276e-59 -3.90152543e-59  1.00398432e-59  1.10930246e-36\n",
      " -1.47514097e-35 -1.03935824e-36 -4.25139153e-36  3.38301250e-35\n",
      " -9.01762899e-36  2.63209016e-39  7.51017059e-35 -1.81933759e-35\n",
      " -1.19922892e-35  3.36696046e-35  9.82046572e-36  5.47937772e-35\n",
      " -3.26089950e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "54 837\n",
      "alpha:         [-1.63184963e-34  4.53589093e-35 -3.36656503e-33 -2.76226042e-42\n",
      "  7.72750305e-34  7.05404665e-34  5.19787237e-33 -2.74395321e-58\n",
      " -2.87952174e-35  2.52459025e-34  4.03620905e-38 -3.06542938e-33\n",
      "  4.65409359e-58 -3.20053036e-33]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "55 260\n",
      "alpha:         [ 1.52730833e-50  5.55043916e-26  2.34873651e-26  3.73062553e-26\n",
      "  2.61133842e-26  1.84602132e-26  1.67714005e-26 -4.52662432e-28\n",
      "  3.23867418e-26 -2.31327963e-27  3.06478246e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "56 1149\n",
      "alpha:         [ 9.12452904e-22 -1.91639247e-46  7.68274926e-23 -1.27451970e-22\n",
      "  1.08885360e-22 -8.35173090e-23  6.42754918e-22 -7.19939059e-22\n",
      " -1.05871235e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "57 1055\n",
      "alpha:         [-1.48545336e-34 -8.05075322e-36 -4.82503550e-35 -1.13182083e-59\n",
      " -6.40620503e-36  1.11696016e-35 -3.51201269e-35  4.08858616e-35\n",
      "  6.25086861e-35  1.75487993e-59 -1.69226214e-35 -4.33579131e-35\n",
      " -3.19506978e-36 -6.44366734e-35  1.82646710e-36  3.36349780e-35\n",
      "  7.30677223e-36  5.80374394e-36  3.63512585e-35 -5.02848633e-36\n",
      "  1.52976755e-35  3.92322101e-35 -7.28143071e-35 -7.24906526e-38\n",
      "  8.63643049e-35]\n",
      "softmax alpha: [0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04\n",
      " 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04]\n",
      "==================================================\n",
      "58 1420\n",
      "alpha:         [ 1.21301643e-22  1.32405942e-22  3.35682587e-22 -1.07183807e-22\n",
      "  1.97931442e-22  1.42871125e-26  3.75838035e-22 -1.19759538e-22\n",
      "  2.97965981e-46]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "59 1462\n",
      "alpha:         [ 1.28749368e-19  8.40241652e-21 -4.55824605e-20 -3.28305139e-20\n",
      " -6.07888563e-20  3.17138834e-20  7.63008193e-21 -9.99238382e-22]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "60 823\n",
      "alpha:         [ 2.38190742e-22  1.03319257e-21 -5.61621892e-47  1.86178700e-22\n",
      "  1.59038265e-22 -3.50940472e-22  2.92634414e-22  3.47796841e-24\n",
      " -1.91684512e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "61 1000\n",
      "alpha:         [ 2.34299093e-33 -2.56230529e-33  8.85825810e-33  2.16516026e-33\n",
      "  1.11709397e-32 -7.04982171e-34  7.09021116e-58  6.87152886e-33\n",
      "  4.20948672e-33  1.76688365e-33  4.04592946e-34  8.16326963e-34\n",
      "  4.22022927e-38  1.36859053e-32]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "62 553\n",
      "alpha:         [-1.14318362e-22 -3.29531746e-46  7.47770691e-23  6.07420915e-22\n",
      "  4.63309263e-22 -5.68597820e-23  3.45000193e-22  1.90738236e-26\n",
      " -2.39599276e-46]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "63 727\n",
      "alpha:         [-7.83603580e-20  1.82274555e-19  2.58964997e-20  4.66315941e-20\n",
      "  2.05329914e-19  1.07511531e-19  1.70061740e-19  1.27355155e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "64 1072\n",
      "alpha:         [ 1.80586207e-20 -4.54428338e-20 -2.33761246e-20 -3.41267422e-20\n",
      " -6.77936127e-20 -2.98179534e-29  1.27759328e-21  5.62687849e-44]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "65 1247\n",
      "alpha:         [ 1.07318574e-24  9.55261673e-25  1.46755042e-24  1.24342919e-23\n",
      "  8.43132574e-24  2.28769387e-24  4.83991398e-48 -3.23749265e-24\n",
      "  8.02100360e-27  6.00891515e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "66 680\n",
      "alpha:         [-3.15149035e-35 -7.16555545e-36 -9.48242932e-35 -1.28413211e-35\n",
      " -1.59828208e-35 -1.08565933e-34 -3.05163364e-35 -1.70450433e-35\n",
      " -5.91988436e-35  2.44161011e-36 -2.60803695e-36 -1.43498616e-36\n",
      " -3.20440253e-35  3.28497175e-40 -5.26049289e-35  1.68522039e-35\n",
      " -4.72088159e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "67 1076\n",
      "alpha:         [-5.33901726e-20 -4.78100131e-22  2.06215671e-19  1.89527691e-20\n",
      "  2.54707811e-20 -9.56458604e-22 -1.24421336e-19  2.35799369e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "68 1388\n",
      "alpha:         [-2.15797731e-28 -1.02814724e-27 -2.76567482e-26 -5.89376548e-51\n",
      " -2.46157805e-26  1.21822619e-26  2.02799561e-26  8.59327753e-27\n",
      "  3.47648987e-30  1.22013133e-26  2.17483850e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "69 304\n",
      "alpha:         [-1.64783359e-24  1.94113205e-25  1.06527073e-26  6.06897711e-24\n",
      "  6.51309013e-24  2.31802540e-25  1.09444682e-24  9.77592356e-24\n",
      "  2.69456530e-24  1.46856679e-23]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "70 1392\n",
      "alpha:         [-2.47318700e-35  4.55108598e-35 -2.61378048e-35 -3.24749378e-35\n",
      " -2.91325799e-59 -8.00414571e-36  7.49585469e-35  8.49334381e-36\n",
      " -1.74943832e-35 -1.22977198e-34 -3.25292432e-44 -1.27937835e-34\n",
      " -1.60422505e-34  4.11011466e-37 -4.67088636e-35 -3.32769842e-35]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "71 486\n",
      "alpha:         [-9.63199537e-24 -4.98479517e-24  3.24646195e-48 -1.05969625e-24\n",
      " -1.11275225e-28 -3.94213069e-24 -9.52976201e-24 -9.47781085e-24\n",
      " -1.50259486e-24 -1.05007590e-23]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "72 360\n",
      "alpha:         [-3.34042786e-36 -4.10859951e-34 -1.77300174e-34 -3.20602776e-34\n",
      "  5.09588845e-35 -1.93001549e-35 -3.58621464e-34  5.97035857e-36\n",
      "  1.70353893e-58 -8.77511021e-59  4.69988788e-36 -2.53052587e-35\n",
      " -8.47982347e-35 -7.34609741e-35  1.33644657e-34]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "73 808\n",
      "alpha:         [ 1.82025788e-27  9.10677157e-27 -1.18509620e-32 -8.86047701e-27\n",
      " -4.19003994e-28  1.45399179e-35  7.26846895e-27 -3.97526399e-27\n",
      "  2.71126907e-26  7.27615215e-27  2.31773478e-50]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "74 792\n",
      "alpha:         [-8.58482888e-35  3.91540814e-35  1.75629791e-34  1.38734487e-35\n",
      "  7.23267947e-37 -6.95660286e-59  2.88718115e-34  1.91617255e-36\n",
      "  2.86677390e-44 -4.55485275e-35 -1.33648145e-34 -2.34056896e-34\n",
      " -6.58058781e-59  3.97392928e-35  6.53630351e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "75 1177\n",
      "alpha:         [-1.04042301e-28 -1.39609045e-26  9.27091015e-27  1.49826567e-26\n",
      " -6.27357104e-27  5.19795561e-27  2.80147219e-27  1.11878767e-26\n",
      " -2.53347059e-27  1.18538322e-26  1.03224495e-51]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "76 55\n",
      "alpha:         [-4.72787369e-24 -1.15244615e-24  5.37816930e-26 -3.82593325e-24\n",
      " -7.65105135e-24 -3.32400595e-24  1.18087312e-23 -2.03450387e-24\n",
      "  2.76854411e-24 -1.70204207e-26]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "77 1539\n",
      "alpha:         [-1.00946797e-28 -5.24752219e-29 -9.37633684e-29 -2.73658696e-30\n",
      " -7.84445713e-31 -9.07323665e-30  2.93053832e-29  2.46096525e-29\n",
      "  1.29326170e-29  9.77592133e-29 -1.02286622e-29  7.48141038e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "78 1445\n",
      "alpha:         [-1.45798294e-34 -7.19316986e-35 -7.73549630e-35 -6.70438398e-35\n",
      " -7.77188988e-35 -1.11223558e-34 -2.94057833e-36 -1.79912447e-35\n",
      " -8.08582525e-35 -7.78283057e-35 -4.83195408e-38 -4.28738733e-44\n",
      " -4.69052083e-36 -1.94617041e-35 -3.56359657e-35 -7.82306953e-59]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "79 1249\n",
      "alpha:         [-5.68199513e-38  2.08002225e-36 -1.28342178e-34 -3.98940600e-35\n",
      "  1.86037015e-35 -1.63402508e-35 -7.75164238e-35  1.82632759e-36\n",
      " -7.63873687e-35  6.67391829e-35 -3.77618744e-46 -1.15802005e-35\n",
      "  4.72818405e-35  1.92835323e-35 -8.57573535e-35  1.50274646e-34\n",
      " -4.71834719e-35 -5.32451060e-59  1.35779608e-35  9.21245284e-37\n",
      " -6.20728142e-36]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "80 1205\n",
      "alpha:         [ 4.76758957e-20 -2.47953465e-45  6.62613446e-21  1.91248685e-21\n",
      "  2.62865072e-20  7.75467610e-20  5.24675692e-20  2.96819346e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "81 420\n",
      "alpha:         [-3.97298413e-27 -1.50238722e-26 -9.88973408e-31 -1.92862177e-27\n",
      " -3.09815921e-27 -4.90170430e-28  5.19200791e-27 -2.75273810e-27\n",
      " -3.38049590e-26 -3.26867918e-27 -3.30208907e-50]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "82 989\n",
      "alpha:         [-2.03829211e-59  7.49799824e-35  1.13342885e-35  7.92585497e-36\n",
      " -4.51744202e-36  1.37376217e-34 -1.83465645e-35  4.96875152e-36\n",
      "  3.44809363e-35  2.16195220e-34  3.63273898e-35  6.17036905e-36\n",
      "  1.97145338e-38  1.18683792e-34  1.81617930e-35  1.36729100e-35\n",
      " -6.36331042e-36 -8.56810436e-36  3.84887158e-35  1.63710552e-35\n",
      " -4.93873554e-59  7.81129850e-37  5.72025848e-35  4.66326267e-35\n",
      " -1.13330891e-35  3.94286514e-35  1.04957455e-34 -4.92872215e-35\n",
      " -2.06781528e-37 -4.09611840e-35  3.27401262e-35 -6.23881397e-35\n",
      "  8.99996059e-35  2.59852912e-35  9.64521998e-35  8.67455909e-36]\n",
      "softmax alpha: [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "==================================================\n",
      "83 211\n",
      "alpha:         [ 2.50860881e-42  2.47851297e-40 -1.44537524e-33  1.39197658e-35\n",
      "  3.03223267e-41  1.16819500e-33  8.99973334e-34 -3.77714762e-34\n",
      "  2.22246995e-34 -6.77485600e-34  5.20774105e-34 -4.45232156e-34\n",
      " -1.31121739e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "84 721\n",
      "alpha:         [-4.04283503e-22 -1.49309807e-20  7.18909088e-20 -1.78090883e-19\n",
      "  1.46551235e-19 -5.45983861e-20 -1.73315606e-20  9.57763487e-45]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "85 45\n",
      "alpha:         [ 6.05240043e-35 -3.45204957e-35  2.27000752e-35  2.32985983e-44\n",
      " -6.42045375e-36 -1.30253680e-35 -5.59731022e-36  1.53703780e-35\n",
      " -4.57627794e-36  1.40566096e-59  9.17107530e-35  1.12779674e-35\n",
      " -3.06004213e-36 -3.51070028e-35  2.81309605e-35  1.06133138e-35\n",
      " -3.52105741e-36  1.03437743e-35 -1.32344621e-35]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "86 1509\n",
      "alpha:         [ 3.68404975e-46 -1.70239419e-22  6.25611798e-22 -3.05465056e-22\n",
      "  8.79353782e-23 -1.81042518e-22 -1.22480241e-46 -4.91308197e-22\n",
      " -7.19264912e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "87 942\n",
      "alpha:         [-5.11205314e-35  6.94023832e-35 -1.07153141e-35  2.26740683e-36\n",
      "  1.03334957e-35  7.26334982e-35 -3.70774290e-35 -1.23578503e-34\n",
      " -1.17599361e-34  1.32971981e-35  2.79175789e-35 -2.70702841e-35\n",
      "  6.88642988e-40 -8.71691872e-35 -1.83106944e-35 -3.63454090e-35\n",
      " -2.56267539e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "88 595\n",
      "alpha:         [-4.42857211e-21  9.38617078e-20  2.46472604e-23 -2.58777958e-20\n",
      " -4.90803293e-21 -1.13415588e-19 -2.25864523e-19 -1.48720837e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "89 824\n",
      "alpha:         [-6.50672502e-36 -2.86609838e-33 -1.45853715e-34  3.26475680e-34\n",
      " -3.38346270e-34 -2.80864470e-33 -1.05875328e-33 -3.72402880e-34\n",
      " -5.97960222e-34 -1.18658455e-57  3.57897059e-34 -2.48257184e-33\n",
      " -2.24465217e-58]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "90 788\n",
      "alpha:         [-2.17531823e-26  2.74658474e-27 -5.46586313e-27 -4.65954294e-26\n",
      " -2.14798346e-26 -7.08494713e-27 -3.83235491e-26 -2.74989527e-26\n",
      " -5.63992594e-26  6.16172215e-51 -1.07052282e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "91 349\n",
      "alpha:         [ 7.79033098e-21 -1.14464629e-20 -7.12699482e-44 -5.52668972e-20\n",
      " -1.02713518e-19  3.52764966e-20 -6.80072609e-20 -1.51662470e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "92 1461\n",
      "alpha:         [-3.93324514e-22 -1.00860227e-19  2.55812154e-29 -1.14747753e-20\n",
      "  3.86326383e-20  1.69267214e-22  5.75550673e-21 -1.61577768e-43]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "93 183\n",
      "alpha:         [ 2.25013962e-29 -1.91852415e-53  1.50486580e-29 -5.88831985e-30\n",
      "  4.86138092e-29  1.21317968e-33  5.49782011e-29  2.89119225e-29\n",
      "  6.62606117e-30  2.59363960e-30  5.87609631e-54 -2.11479814e-30]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "94 82\n",
      "alpha:         [ 1.61813719e-35 -1.01719065e-60  4.19010285e-35 -4.41809824e-60\n",
      " -3.58866623e-36 -2.96250267e-35 -1.26196106e-59  2.77616937e-35\n",
      "  6.41204225e-36 -2.12298460e-35  2.23177292e-35  2.35307486e-36\n",
      " -2.89941098e-36 -3.23191813e-35 -1.27429709e-35  3.34889921e-36\n",
      "  3.08016363e-35  3.17030084e-35  4.08475659e-35  3.75300787e-35\n",
      " -2.98667858e-35 -1.64111829e-36  3.31310095e-35  1.66614899e-36\n",
      "  7.82561650e-35  1.15382864e-34  2.01044902e-35  3.53362237e-35\n",
      "  3.82690188e-37 -3.51935655e-35  1.93023995e-59  1.15952029e-38\n",
      "  2.64007430e-35]\n",
      "softmax alpha: [0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303]\n",
      "==================================================\n",
      "95 102\n",
      "alpha:         [-4.04769288e-35 -3.61433007e-35 -9.12171372e-36  9.69310393e-36\n",
      "  1.52472502e-35  3.92807004e-35 -2.19012618e-35 -7.46616241e-35\n",
      " -3.10874409e-35 -5.35648706e-59  2.53554866e-36 -1.94411261e-35\n",
      " -8.46652663e-36  2.17210883e-36 -6.18891360e-36 -2.83240425e-35\n",
      "  1.05868702e-39]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "96 1252\n",
      "alpha:         [ 1.04540343e-34  7.55134058e-33  2.41354342e-33  1.26775365e-33\n",
      "  1.30000075e-32  8.39417830e-34  4.29424323e-57  1.86579339e-34\n",
      "  6.45284760e-34  2.13737581e-32  1.94611286e-57  7.99416233e-33\n",
      "  2.65012726e-33 -2.60809004e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "97 324\n",
      "alpha:         [ 2.00529747e-24 -4.60895252e-20  1.95884806e-29 -5.66582724e-21\n",
      "  3.59228036e-20 -4.89562844e-21 -6.01735948e-21  1.98688295e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "98 1514\n",
      "alpha:         [ 4.12610232e-34  9.66105990e-34  1.09931281e-33 -4.41849832e-34\n",
      "  2.34594957e-33  1.08674474e-33 -2.37824172e-34  2.50459998e-58\n",
      "  8.52681080e-34 -1.23293348e-33  1.75162884e-33 -8.48960325e-34\n",
      "  1.60517901e-33]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "99 968\n",
      "alpha:         [-7.25895274e-35 -3.41559045e-59 -1.61998979e-34 -1.17386565e-34\n",
      "  7.87453480e-36 -1.23448955e-35  1.68151985e-35  2.24001553e-35\n",
      " -6.14616689e-35  5.21225209e-35 -1.50185318e-35  2.60532633e-35\n",
      " -2.22617097e-35 -1.40147912e-37  1.07711741e-45 -5.28969565e-35\n",
      "  1.75017717e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "100 181\n",
      "alpha:         [-1.31985553e-37 -3.73366807e-35  3.98031173e-35  1.35045986e-59\n",
      "  2.62803939e-36  1.72415625e-35  1.75589972e-59 -1.57465837e-35\n",
      "  3.37283820e-35  3.50905323e-35  1.43763678e-35  8.63596317e-38\n",
      "  2.54000429e-37  2.43302094e-36  5.79673350e-35  1.07671721e-34\n",
      "  5.16461259e-36 -3.48760984e-35  1.89465939e-35 -1.40427864e-37]\n",
      "softmax alpha: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "==================================================\n",
      "101 733\n",
      "alpha:         [ 1.15861720e-19 -7.08067820e-21  4.77546191e-20  9.21546210e-20\n",
      "  8.01083856e-20  2.36052737e-19  1.79058191e-23 -1.08116757e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "102 1189\n",
      "alpha:         [-5.39995550e-29  7.82500078e-30  1.05743011e-38  1.49533505e-29\n",
      " -5.49383906e-30 -4.24194442e-29 -3.17685573e-30 -7.31554633e-55\n",
      "  3.99491605e-29 -3.31851637e-54 -1.19745300e-29 -2.19805531e-30]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "103 1089\n",
      "alpha:         [-9.50340088e-27  4.50755982e-26  1.22035042e-27  5.21226107e-28\n",
      "  7.46957758e-27  2.90678327e-27  1.46599473e-26  6.69325470e-26\n",
      "  3.43967304e-26 -2.11773617e-26  1.10088834e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "104 943\n",
      "alpha:         [-1.95068484e-24 -2.79918369e-23 -6.65848554e-24  4.58069571e-25\n",
      " -5.08301626e-24 -1.69963456e-23 -2.16909415e-24 -1.22380740e-24\n",
      " -1.31394045e-23 -4.04786359e-30]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "105 1279\n",
      "alpha:         [-5.52975737e-29 -2.86684174e-27  9.78322977e-28 -1.24817007e-26\n",
      " -5.00408326e-27  1.36081742e-50  2.32983455e-31  9.89568645e-27\n",
      " -2.64746439e-27  8.31410287e-28  1.68320528e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "106 906\n",
      "alpha:         [ 3.00667603e-24  1.51468569e-24 -1.48590382e-25 -3.06177464e-25\n",
      " -7.24467828e-24  1.09121050e-24 -1.18761535e-23  1.13687013e-24\n",
      " -1.60936322e-25 -1.10625244e-48]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "107 1080\n",
      "alpha:         [-3.31611300e-35  1.62436852e-34 -3.24127042e-35 -1.09942655e-35\n",
      " -1.03840962e-35 -1.57236301e-59 -1.00459011e-34  4.90855336e-35\n",
      "  1.13267213e-36  2.16618385e-35 -7.92172955e-36  8.72028562e-36\n",
      " -2.08415300e-35 -1.12432589e-35 -3.04118766e-35  1.19460277e-35\n",
      "  6.17185509e-36 -9.43829517e-37  1.12554355e-39]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "108 1543\n",
      "alpha:         [ 1.30843969e-34 -9.37832008e-35 -1.05774217e-35  3.73482091e-35\n",
      "  1.09289314e-34  3.74396364e-35  8.79457733e-36  6.24683437e-35\n",
      "  1.61099868e-35 -1.48471307e-35  1.49682009e-59 -1.61815527e-35\n",
      " -6.89260452e-36 -6.78594081e-36  8.40173419e-35  1.19845020e-35\n",
      "  8.08526816e-37]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "109 1081\n",
      "alpha:         [-1.24355139e-19 -3.74313348e-20 -3.45257042e-20  3.36674833e-21\n",
      " -3.59900134e-19 -6.91555006e-26  5.72849299e-20 -3.12190883e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "110 1186\n",
      "alpha:         [-1.81506361e-24  4.89783891e-24  9.19228752e-25  6.43758221e-25\n",
      "  1.65031926e-24  5.86967290e-25  1.68823494e-24 -1.96573152e-24\n",
      "  5.97558660e-24 -1.57757888e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "111 547\n",
      "alpha:         [ 1.40394841e-21  1.11327612e-22 -1.11421683e-45  1.89989167e-22\n",
      "  1.67263866e-22  1.47918803e-21  4.82443275e-24  6.49413187e-22\n",
      "  5.87786205e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "112 548\n",
      "alpha:         [ 2.60790338e-25 -6.13050747e-24 -3.15009777e-24  1.51808470e-25\n",
      "  1.96264871e-24  5.87476301e-24  1.75390384e-23 -1.27396558e-23\n",
      "  3.29272669e-48  1.15014440e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "113 708\n",
      "alpha:         [-1.33602801e-54  4.03054220e-29 -1.66899075e-28  2.65585347e-53\n",
      "  2.58665176e-29  3.18570193e-29 -4.43108577e-30  5.50274246e-29\n",
      "  3.74248200e-31  1.46708048e-38  3.27005620e-30  1.20051054e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "114 1050\n",
      "alpha:         [-9.50228222e-21 -1.25652434e-19  4.19150710e-22  1.53419548e-20\n",
      " -6.96262034e-21 -1.25697489e-20  4.22963779e-20 -3.76808292e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "115 682\n",
      "alpha:         [-5.29831237e-22 -1.83033432e-21  4.20484811e-20  2.47790521e-20\n",
      " -1.60429752e-20  1.04896906e-28  4.47335493e-20  3.86271231e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "116 129\n",
      "alpha:         [-6.88811910e-20  5.18235217e-20  8.15917463e-45  6.96429273e-20\n",
      "  5.85433593e-20  1.35386432e-26  2.78123340e-44  2.01999098e-22]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "117 1109\n",
      "alpha:         [ 5.47936179e-35  3.63178102e-35  4.83609929e-36  3.56195094e-35\n",
      "  5.47128717e-60  3.47080181e-35 -1.74894755e-59  1.04432995e-34\n",
      "  7.70641866e-36 -3.45199663e-36  7.74801678e-36  3.66670441e-35\n",
      "  6.15326953e-35  3.78587068e-35  1.01775776e-40  2.92653450e-37\n",
      "  6.18083123e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "118 1037\n",
      "alpha:         [ 1.07186374e-20 -1.10843721e-19 -5.20316946e-20 -3.42996563e-19\n",
      " -3.45580848e-45  1.99843552e-21 -1.20379276e-19 -1.78681982e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "119 49\n",
      "alpha:         [-1.66331660e-36 -8.28987286e-35 -1.36305036e-59 -5.45747284e-35\n",
      " -7.61710909e-35  9.17857673e-35  2.92793897e-34  1.27082292e-34\n",
      "  4.28405247e-36  1.55868515e-35  4.61501995e-41  5.13714377e-35\n",
      " -3.22166557e-34 -5.51544689e-35 -4.41163469e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "120 258\n",
      "alpha:         [-2.24690864e-20  3.31978673e-19 -3.84192195e-20  5.13014303e-20\n",
      " -2.72383835e-29  1.36402650e-19 -6.18596981e-20  1.73048149e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "121 754\n",
      "alpha:         [-9.32523568e-26  6.70004379e-24  3.13435504e-24 -3.44276279e-50\n",
      "  1.03143546e-25 -1.10606732e-24 -4.73364941e-25 -1.87770501e-24\n",
      " -3.52162672e-24  1.42871685e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "122 840\n",
      "alpha:         [ 1.82558767e-48 -1.59105923e-25  2.00059027e-24 -2.62604662e-24\n",
      "  5.41230289e-25  7.54913155e-24  3.70412650e-24  3.32135838e-25\n",
      "  1.07438037e-28  8.51424563e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "123 1271\n",
      "alpha:         [ 8.66922497e-22 -1.34874018e-20 -1.25557889e-19  3.13018873e-20\n",
      " -1.18522903e-20  3.09037142e-44 -8.04280798e-21 -1.36634925e-29]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "124 1196\n",
      "alpha:         [ 3.27489029e-20 -6.12747152e-20  4.29777206e-20  1.01103612e-19\n",
      " -1.85405875e-19  6.42545235e-46 -8.21833200e-22 -1.78148608e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "125 1355\n",
      "alpha:         [ 6.00466395e-20  7.87791927e-29  6.12634205e-20 -5.58437000e-22\n",
      " -8.93811409e-21  5.52651601e-20  5.84440243e-44  4.69341326e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "126 136\n",
      "alpha:         [-1.33596056e-27  1.58500181e-26  5.55309205e-26 -3.05322044e-26\n",
      " -1.96039306e-26 -6.16063704e-27 -8.08878521e-27 -2.67654809e-26\n",
      " -8.28248773e-28 -3.17262839e-26 -2.92553671e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "127 110\n",
      "alpha:         [-3.88597693e-35 -9.00804950e-35 -1.55443134e-35 -3.08365602e-35\n",
      " -1.73918779e-59  1.47648930e-35 -4.14045564e-36  1.53399661e-35\n",
      " -4.35812083e-37 -1.82041729e-34 -2.50949971e-35 -2.83073087e-35\n",
      " -3.92466152e-37  5.66383421e-35 -1.93363743e-34  2.93841474e-35\n",
      "  4.55584850e-36]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "128 1255\n",
      "alpha:         [ 6.46332168e-20  1.71284092e-21 -2.21529926e-19 -3.75148945e-20\n",
      " -1.99107449e-44 -1.15963055e-19 -6.37425314e-44 -5.15105989e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "129 510\n",
      "alpha:         [-9.40768750e-24 -5.93985060e-23 -3.29274023e-22 -1.48158551e-21\n",
      " -2.04705509e-22 -1.32086288e-22 -9.08971878e-22 -2.81676947e-23\n",
      "  2.96481427e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "130 1364\n",
      "alpha:         [-1.13413749e-24 -4.60602870e-24  8.05404042e-49 -1.67332789e-24\n",
      " -6.87495506e-24 -4.36833265e-24 -1.08501206e-48 -2.51490781e-23\n",
      "  1.33277029e-24 -7.30236669e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "131 1510\n",
      "alpha:         [ 9.39427400e-45  1.94254289e-20  1.48789402e-20 -2.34354040e-20\n",
      " -1.51826381e-20  9.07955366e-20  2.62168482e-21 -8.76718376e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "132 718\n",
      "alpha:         [ 7.12524777e-36 -6.13949827e-35 -5.48973658e-35 -3.64907054e-36\n",
      " -6.20947983e-35 -5.08277698e-36 -1.54386259e-34  5.61703132e-36\n",
      " -1.57048372e-39 -3.61650864e-35 -3.42928319e-35  2.33015326e-36\n",
      " -8.06666627e-35  5.19333375e-59  2.64951056e-36 -8.15333598e-36\n",
      " -8.55205432e-36  1.28276532e-35 -4.52789033e-38  7.64990452e-36\n",
      " -8.61942154e-36 -6.60989032e-35 -6.46818016e-36  1.13415568e-59\n",
      "  9.65343002e-60 -2.05562390e-35 -4.31261338e-35  1.03981305e-35\n",
      " -1.42632071e-34  3.51305515e-36 -4.83044652e-35 -6.69047360e-35\n",
      " -6.31554979e-35]\n",
      "softmax alpha: [0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303]\n",
      "==================================================\n",
      "133 865\n",
      "alpha:         [-8.41323009e-27 -2.59069740e-24 -1.27880278e-24  2.31860679e-24\n",
      "  2.19820525e-25  3.47175393e-24 -1.11173320e-24 -5.53071014e-25\n",
      " -1.96085688e-24 -9.73020994e-25]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "134 713\n",
      "alpha:         [-3.66970610e-24  7.88682746e-25  1.18599278e-24  2.37451139e-24\n",
      "  1.85070060e-25  8.95713878e-49  4.35901260e-49 -5.04427289e-35\n",
      " -3.88507554e-26  3.10278176e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "135 325\n",
      "alpha:         [-4.26146272e-24 -1.75381770e-24 -4.53035047e-26 -5.27110130e-24\n",
      " -2.49561367e-28 -6.63381847e-24 -8.16177488e-24 -6.14104631e-25\n",
      " -1.31252393e-23 -2.49128352e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "136 1507\n",
      "alpha:         [ 7.87866826e-29 -8.48279037e-30  4.84476340e-29  7.98878439e-35\n",
      " -2.83012928e-39 -1.96607096e-29  6.95794009e-54 -3.10690168e-30\n",
      "  1.14290302e-29 -4.85962713e-30  2.44225860e-31 -2.37100304e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "137 1549\n",
      "alpha:         [ 5.63984749e-27  2.03410384e-27  1.30468665e-26 -1.18873256e-26\n",
      " -4.97066606e-26 -4.27349837e-27  9.44869806e-27  3.79137090e-27\n",
      "  6.12884547e-27 -4.03689179e-27  3.15408263e-28]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "138 1379\n",
      "alpha:         [ 9.73338715e-36 -2.20855959e-37 -4.68745263e-35  9.16663716e-35\n",
      "  3.16926902e-35  1.71222374e-35  6.69751618e-37  3.47087321e-35\n",
      "  3.16983096e-35 -1.36818377e-39  7.29499498e-35  5.23907785e-36\n",
      "  5.76163589e-35 -7.26529696e-36  8.98477132e-36  2.88814495e-35\n",
      " -3.27936862e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "139 1179\n",
      "alpha:         [ 8.34950510e-36 -1.02150751e-34 -1.43044076e-35 -1.54996222e-34\n",
      " -2.89260731e-36 -2.77957456e-35  4.02596702e-35  1.44073143e-40\n",
      " -6.51776359e-35 -1.40282953e-35 -6.58909320e-36 -3.93646674e-35\n",
      "  5.81294062e-35 -1.30485778e-35  9.11960840e-36 -5.82100973e-36\n",
      "  2.93072043e-36  9.24980969e-36]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "140 1086\n",
      "alpha:         [-5.76747724e-35 -2.56522058e-35 -4.01263498e-35  5.51849785e-35\n",
      "  1.83790001e-35  7.82788871e-35  1.12460036e-35 -1.83490209e-34\n",
      " -2.75993119e-35  1.31572372e-35 -1.63668589e-35  9.20480055e-36\n",
      "  2.07468334e-41  4.12259574e-36 -3.16432869e-35  1.77472317e-35]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "141 438\n",
      "alpha:         [-1.20813142e-21 -1.08143177e-21  1.30340258e-23 -6.36481673e-22\n",
      " -1.22264744e-22  5.64096811e-46  1.12693157e-22  3.57303898e-28\n",
      "  3.96034387e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "142 450\n",
      "alpha:         [-4.14894842e-24 -1.02164817e-24 -2.18796774e-24 -3.59949652e-24\n",
      " -8.35751577e-24 -2.34368691e-24 -7.73135637e-25  1.05019809e-23\n",
      "  3.53364252e-25  3.06824978e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "143 43\n",
      "alpha:         [-1.77126604e-33 -1.41796350e-36 -2.70263936e-34  1.82465887e-34\n",
      " -4.05334143e-34 -1.93771243e-33 -2.41676793e-33  3.97351408e-35\n",
      "  4.28035032e-34 -2.87142937e-33 -5.09162237e-33  2.33931790e-34\n",
      " -4.14171101e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "144 607\n",
      "alpha:         [ 6.20663246e-59  9.71727059e-36  3.08487443e-35  6.85613804e-59\n",
      "  7.13752821e-35  7.11206349e-35  3.02233152e-35 -4.40849001e-35\n",
      "  3.45175490e-35  2.08415914e-35 -2.07411926e-35  7.14729920e-35\n",
      " -1.60243339e-36 -1.51112834e-36  1.28870349e-36  1.86342797e-36]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "145 237\n",
      "alpha:         [-1.85266967e-19 -1.08526148e-31 -1.12838028e-19 -1.48094725e-20\n",
      "  6.75134267e-20 -1.35960338e-19 -1.50691482e-20 -5.65025814e-23]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "146 1518\n",
      "alpha:         [-3.90928169e-24  1.35624817e-24  3.00550391e-24  1.65970752e-24\n",
      "  2.93932890e-24  3.84303101e-24  5.13234013e-25  1.81555208e-48\n",
      "  1.88598304e-48 -1.93929316e-23]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "147 513\n",
      "alpha:         [ 5.60478834e-36 -1.84475746e-58  6.20284890e-36  2.84339547e-34\n",
      " -1.31811410e-34 -1.71071036e-58 -1.68407694e-35 -8.94632272e-35\n",
      "  1.36064518e-34  5.15941508e-36  3.15693375e-34  6.12694000e-34\n",
      "  7.19319416e-36  5.54633759e-38 -6.12005378e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "148 861\n",
      "alpha:         [-8.24432020e-49  2.70763705e-24 -6.07518359e-48 -1.19663661e-24\n",
      "  1.42056472e-24  1.51055614e-23  9.46456010e-25  3.76058375e-25\n",
      " -3.07629847e-24 -1.29049784e-48]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "149 1557\n",
      "alpha:         [ 1.36455334e-33  4.67547960e-34 -1.32624295e-33  6.05874188e-34\n",
      "  3.47164899e-33  3.46735624e-57  1.05381506e-36  1.05648181e-37\n",
      "  2.42671940e-33  1.44908553e-33 -1.84276366e-34  1.33232735e-42\n",
      "  6.25685241e-33  3.51516713e-33]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "'''\n",
    "\n",
    "#with Embedding\n",
    "result = np.zeros((usr_test_amount, movie_nb))\n",
    "RS = np.zeros((usr_test_amount, movie_nb))\n",
    "#test_idx --> Test 的 index\n",
    "\n",
    "test_yes_id = []\n",
    "\n",
    "for s in range(usr_test_amount):\n",
    "    print(s, test_idx[s])\n",
    "\n",
    "    yes = []\n",
    "    sample = random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #從training part 的positive feedback 取出YouTuber 當成Auxilary\n",
    "    #sample=result_yes_id[now]\n",
    "    test_yes_id.append(sample)\n",
    "    alpha = np.zeros([len(sample)])\n",
    "    \n",
    "    for a in range(len(sample)):\n",
    "        r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "        #print(test_idx[s])\n",
    "        #print(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0)))\n",
    "        alpha[a] = np.dot(A1[test_idx[s]],(relu(np.dot(Au,np.expand_dims(U[test_idx[s]],0).T) +\n",
    "                                                np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T) +\n",
    "                                                np.dot(Aa,np.expand_dims(A[sample[a]],0).T) +\n",
    "                                                np.dot(Av,np.expand_dims(all_npy[sample[a]],0).T)))) * r\n",
    "    mul = np.zeros((1,latent_dim))\n",
    "    \n",
    "    print(\"{:<15}{}\".format('alpha:', alpha))\n",
    "    print(\"{:<15}{}\".format('softmax alpha:', softmax(alpha)))\n",
    "    print('==================================================')\n",
    "    \n",
    "    for i in range(len(sample)):\n",
    "        mul += softmax(alpha)[i] * A[sample[i]] #attention alpha*Ai part \n",
    "    new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "    \n",
    "    for k in range(movie_nb):\n",
    "        result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "        RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "#print(RS[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#取出test的資料\n",
    "testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150*20\n",
    "target = np.zeros((usr_test_amount, movie_test_amount))\n",
    "#test_t 是true的\n",
    "#test_f 是false的\n",
    "        \n",
    "for z in range(usr_test_amount):\n",
    "    user_id = test_idx[z]\n",
    "    #positive target YouTuber list\n",
    "    youtube_t = test_t[z] \n",
    "    #not target YouTuber list\n",
    "    youtube_f = test_f[z]\n",
    "    \n",
    "    #前兩個放target的RS\n",
    "    for i in range(len(youtube_t)):\n",
    "        testRS[z][i] = RS[z][youtube_t[i]]\n",
    "        target[z][i] = 1\n",
    "        \n",
    "    for i in range(len(youtube_f)):\n",
    "        testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 16) (150, 16)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape, testRS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of positive data in testing: 300.0\n",
      "total testing data: 2400\n"
     ]
    }
   ],
   "source": [
    "sumtarget = 0\n",
    "for i in range(len(target)):\n",
    "    #print(np.sum(target[i]))\n",
    "    sumtarget += np.sum(target[i])\n",
    "print('num of positive data in testing:',sumtarget)\n",
    "print('total testing data:', usr_test_amount * movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),int(np.sum(target[i])))\n",
    "    count_0_all.append(top_0)\n",
    "    #print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = 0\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        #print(int(np.sum(target[i])))\n",
    "        total+=int(np.sum(target[i]))\n",
    "        if count_0_all[i][j] < int(np.sum(target[i])): #代表是0或1 (也就是target)\n",
    "            acc_0 += 1\n",
    "avg_acc = acc_0/100\n",
    "#print('avg_accuarcy for count_0:',avg_acc)\n",
    "#print(acc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),1) #取一個\n",
    "    count_0_all.append(top_0)\n",
    "    #print(np.sum(target[i]))\n",
    "    #print(top_0)\n",
    "    if top_0[0] < int(np.sum(target[i])):\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.20666666666666667 recall  0.10333333333333333\n",
      "F1_score: 0.13777777777777778\n"
     ]
    }
   ],
   "source": [
    "top1_prec = correct/len(testRS)\n",
    "top1_recall = correct/(sumtarget)\n",
    "print('prec ',top1_prec,'recall ',top1_recall)\n",
    "print('F1_score:',F1_score(top1_prec,top1_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_3 = topN(list(testRS[i]),3) #取一個\n",
    "    count_0_all.append(top_3)\n",
    "    #print(top_3)\n",
    "    for j in range(len(top_3)):\n",
    "        if top_3[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.10444444444444445 recall  0.15666666666666668\n",
      "F1_score: 0.12533333333333332\n"
     ]
    }
   ],
   "source": [
    "top3_prec = correct/(len(testRS)*3)\n",
    "top3_recall = correct/(sumtarget)\n",
    "print('prec ',top3_prec,'recall ',top3_recall)\n",
    "print('F1_score:',F1_score(top3_prec,top3_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_5 = topN(list(testRS[i]),5) #取一個\n",
    "    count_0_all.append(top_5)\n",
    "    #print(top_5)\n",
    "    for j in range(len(top_5)):\n",
    "        if top_5[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.076 recall  0.19\n",
      "F1_score: 0.10857142857142857\n"
     ]
    }
   ],
   "source": [
    "top5_prec = correct/(len(testRS)*5)\n",
    "top5_recall = correct/(sumtarget)\n",
    "print('prec ',top5_prec,'recall ',top5_recall)\n",
    "print('F1_score:',F1_score(top5_prec,top5_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "'''\n",
    "all_sort = []\n",
    "pre_matrix = np.zeros(shape=(usr_test_amount, movie_test_amount))\n",
    "for i in range(usr_test_amount):\n",
    "    top_5 = topN(list(testRS[i]),5) #取一個\n",
    "    #print(top_5)\n",
    "    all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "    for j in range(len(top_5)):\n",
    "        pre_matrix[i][top_5[j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 16) (150, 16)\n"
     ]
    }
   ],
   "source": [
    "print(pre_matrix.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG\n",
    "* https://daiwk.github.io/posts/nlp-ndcg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideal DCG，理想状况下的DCG。也就是说，相关性完全由高到低排序时算出的DCG：\n",
    "\n",
    "def IDCG(ideal_list): #ideal_list example = [1,1,1,1,1,0,0,....]\n",
    "    idcg = 0\n",
    "    for i in range(len(ideal_list)):\n",
    "        #print((2**true_list[i]-1),math.log2(i+2))\n",
    "        idcg += (2**ideal_list[i]-1)/math.log2(i+2)\n",
    "    #print('idcg',idcg)\n",
    "    return idcg\n",
    "\n",
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    #print('dcg',dcg)\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.09998938219330257\n"
     ]
    }
   ],
   "source": [
    "total_ndcg = 0\n",
    "num_ndcg = 5\n",
    "for m in range(usr_test_amount):\n",
    "    idcg = IDCG([1]*num_ndcg)\n",
    "    pre_list = []\n",
    "    for s in all_sort[m][:num_ndcg]:\n",
    "        #print(s)\n",
    "        #print(target[m][s])\n",
    "        pre_list.append(target[m][s])\n",
    "    dcg = DCG(pre_list)\n",
    "    ndcg = dcg/idcg\n",
    "    #print(ndcg)\n",
    "    total_ndcg += ndcg\n",
    "avg_ndcg = total_ndcg/usr_test_amount\n",
    "print('NDCG:',avg_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.15258333333333332\n"
     ]
    }
   ],
   "source": [
    "total_prec = 0\n",
    "for u in range(usr_test_amount):\n",
    "    y_true = target[u]\n",
    "    y_scores = pre_matrix[u]\n",
    "    total_prec += average_precision_score(y_true, y_scores)\n",
    "    \n",
    "MAP = total_prec/usr_test_amount\n",
    "\n",
    "print('MAP:', MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
