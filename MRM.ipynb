{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 4876)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_4876.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [[2 1 0 ... 1 0 0]\n",
      " [4 8 4 ... 0 0 0]\n",
      " [2 2 2 ... 1 0 0]\n",
      " ...\n",
      " [5 3 0 ... 1 1 0]\n",
      " [2 2 0 ... 0 1 0]\n",
      " [3 2 0 ... 1 1 0]]\n",
      "After: [[0.22222222 0.11111111 0.         ... 0.11111111 0.         0.        ]\n",
      " [0.44444444 0.88888889 0.44444444 ... 0.         0.         0.        ]\n",
      " [0.4        0.4        0.4        ... 0.2        0.         0.        ]\n",
      " ...\n",
      " [0.26315789 0.15789474 0.         ... 0.05263158 0.05263158 0.        ]\n",
      " [0.28571429 0.28571429 0.         ... 0.         0.14285714 0.        ]\n",
      " [0.33333333 0.22222222 0.         ... 0.11111111 0.11111111 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Before:', usr_genre)\n",
    "print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "\n",
    "print(usr_nb, movie_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 16\n"
     ]
    }
   ],
   "source": [
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "usr_idx = [i for i in range(len(usr_following))]\n",
    "print(len(usr_idx))\n",
    "\n",
    "test_idx = random.sample(usr_idx, usr_test_amount)\n",
    "print(len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "train_t = [0] * usr_nb\n",
    "train_f = [0] * usr_nb\n",
    "# Testing\n",
    "test_t = [0] * usr_test_amount\n",
    "test_f = [0] * usr_test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(usr_following)):\n",
    "    \n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        \n",
    "        for j in range(movie_nb):\n",
    "            \n",
    "            if usr_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        \n",
    "        # random choose 2 true and 8 false for test \n",
    "        t_for_test = random.sample(temp_t, 2)\n",
    "        f_for_test  = random.sample(temp_f, 8)\n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1582\n",
      "The length of train_f: 1582\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "# train_t[i] 代表的是user i positive feedback\n",
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'MRM_ALL_Embedding200'\n",
    "LATENT_FOLDER = './latent_factor/MRM_ALL/Embedding200/'\n",
    "newPath(LATENT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 4876 200\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 200\n",
    "\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None,ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [usr_nb, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [latent_dim,latent_dim], \n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [movie_nb, latent_dim, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [latent_dim, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [latent_dim, ft_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "    ########## Error part, how to get auxisize dynamically\n",
    "    ####aux_size= tf.get_variable(name='aux_size', initializer=l_id.get_shape().as_list()[-1])\n",
    "    \n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.00001,0.000001,seed=10))\n",
    "    \n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "w1 = tf.nn.embedding_lookup(W1, user) #(1*k)\n",
    "wu = Wu\n",
    "#wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user)) #(k*k)\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, i)) #(k*k)\n",
    "wa = Wa\n",
    "#wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user)) #(k*k)\n",
    "wv = Wv\n",
    "#wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user)) #(k,l)\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-15-e975e9415cb9>:76: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,ft_dim)\n",
    "    \n",
    "    a_list = tf.concat([a_list,[(tf.matmul( w1, tf.nn.relu( tf.matmul(wu, u, transpose_b=True) +\n",
    "        tf.matmul(wy, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wa, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wv, xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q,  a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_soft = tf.nn.softmax(a_list)\n",
    "\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    #aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "#tf.print('aux attention:',aux_np)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "norm_par = [tf.reduce_sum(tf.multiply(u, u)),tf.reduce_sum(tf.multiply(vi, vi)),tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "           tf.reduce_sum(tf.multiply(w1, w1)),tf.reduce_sum(tf.multiply(wu, wu)),tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "           tf.reduce_sum(tf.multiply(wa, wa)),tf.reduce_sum(tf.multiply(wv,wv)),tf.reduce_sum(tf.multiply(beta,beta))]\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "  \n",
    "            0.0001 * tf.reduce_sum(tf.multiply(w1, w1)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "            \n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            \n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: Fri Mar  6 00:34:34 2020\n",
      "Iteration: 0\n",
      "total_loss          [[0.08499577]]\n",
      "train_auc:          0.9721809383910827\n",
      "Current time: Fri Mar  6 01:16:30 2020\n",
      "==================================================\n",
      "Iteration: 1\n",
      "total_loss          [[0.03215997]]\n",
      "train_auc:          0.9897088049771019\n",
      "Current time: Fri Mar  6 01:58:29 2020\n",
      "==================================================\n",
      "Iteration: 2\n",
      "total_loss          [[0.01103309]]\n",
      "train_auc:          0.9965739220599672\n",
      "Current time: Fri Mar  6 02:40:27 2020\n",
      "==================================================\n",
      "Iteration: 3\n",
      "total_loss          [[0.00624372]]\n",
      "train_auc:          0.9981875918085198\n",
      "Current time: Fri Mar  6 03:22:28 2020\n",
      "==================================================\n",
      "Iteration: 4\n",
      "total_loss          [[0.00428414]]\n",
      "train_auc:          0.998714680722371\n",
      "Current time: Fri Mar  6 04:04:34 2020\n",
      "==================================================\n",
      "Total cost time: 12599.873953342438\n",
      "End time: Fri Mar  6 04:04:34 2020\n"
     ]
    }
   ],
   "source": [
    "print('Start time:', time.ctime())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_acc_list = []\n",
    "t0 = time.time()\n",
    "\n",
    "#use_true=init_list_of_objects(136)\n",
    "#use_test=init_list_of_objects(136)\n",
    "\n",
    "#train_pair_t=[] #positive feedback\n",
    "#train_pair_f=[] #negative feedback\n",
    "train_yes_id=[]\n",
    "\n",
    "for q in range(5):\n",
    "    print('Iteration:',q)\n",
    "    train_auc = 0\n",
    "    total_loss = 0\n",
    "    xuij_auc = 0\n",
    "    length = 0\n",
    "    \n",
    "    for z in range(usr_nb):\n",
    "        \"\"\"\n",
    "        yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "        yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "        r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "        \"\"\"\n",
    "        yes = []\n",
    "        yesr = []\n",
    "        \n",
    "        sample = random.sample(train_t[z],len(train_t[z])) #隨機選3個sample true's YouTuber\n",
    "        train_yes_id.append(sample) #sample全部丟進去\n",
    "        \n",
    "        #sample=random.sample(train_t[z]+train_f[z],len(train_t[z])+len(train_f[z]))\n",
    "        \n",
    "        #change\n",
    "        r_3 = np.zeros(len(sample)) \n",
    "        alpha_history = []\n",
    "        a_list_history = []\n",
    "        U_history = []\n",
    "        Y_history = []\n",
    "        \n",
    "        #print(len(sample))\n",
    "        #check if all YouTuber are in train_t or train_f\n",
    "        #if len(train_t[z])+len(train_f[z]) != 88:\n",
    "            #print(z,len(train_t[z])+len(train_f[z]))\n",
    "         \n",
    "        for b in range(len(sample)):\n",
    "            yes.append(all_npy[sample[b]])\n",
    "            yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "            #print('YouTuber_category ', YouTuber_category[sample[k]])\n",
    "            #print('User_category ',user_category_norm[z])\n",
    "        #print(len(yes))\n",
    "        \n",
    "        for b in range(len(yesr)):\n",
    "            r_3[b]=max(yesr[b])\n",
    "        #print('r_3:',r_3)\n",
    "        \n",
    "        yes = np.array(yes)\n",
    "        #print('user shape should be ',np.array([z]).shape)\n",
    "        #print('xf shape should be ',yes.shape)\n",
    "        #print('r shape should be ',np.array(r_3).shape)\n",
    "        #print('l_id shape should be ',np.array(sample).shape)\n",
    "        \n",
    "        #not_used_list = list(set(train_t[z]).difference(set(sample)))\n",
    "        \n",
    "        # positive \n",
    "        train_t_sample = random.sample(train_t[z],len(train_t[z]))\n",
    "        #print('number of positive feedback', len(train_t[z]))\n",
    "        # negative\n",
    "        train_f_sample = random.sample(train_f[z],20)\n",
    "        \n",
    "        for ta in train_t_sample:\n",
    "            #print(ta,'--> positive feedback')\n",
    "            \n",
    "            pos = sample.index(ta)\n",
    "            #new_sample = np.delete(sample,[pos])\n",
    "            #new_yes = np.delete(yes,[pos],axis=0)\n",
    "            #new_r_3 = np.delete(r_3,[pos])\n",
    "            new_sample = sample\n",
    "            new_yes = yes\n",
    "            new_r_3 = r_3\n",
    "            #print(len(yes),len(new_yes))\n",
    "            #print(yes)\n",
    "            #print(new_yes)\n",
    "            \n",
    "            #ta=random.choice(train_t[z]) #ta is true positve photo\n",
    "            #train_pair_t.append(ta)\n",
    "            image_1=np.expand_dims(all_npy[ta],0) #(1,2048)\n",
    "            #print('Image_1 shape ',image_1.shape)\n",
    "            #train_f_sample = random.sample(train_f[z],20)\n",
    "            #print('True:',train_t_sample,'Now:',ta)\n",
    "            #print('False:',train_f_sample)\n",
    "            \n",
    "            for b in train_f_sample:\n",
    "                #print('likes:',ta,';Not likes:',b)\n",
    "                #b=random.choice(train_f[z])  #b is no feedback photo\n",
    "                #train_pair_f.append(b)\n",
    "                image_2=np.expand_dims(all_npy[b],0) #(1,2048)\n",
    "                #print('Image_2 shape',image_2.shape)\n",
    "            \n",
    "                #use_test[z].append(b)\n",
    "                _embedding,_a_list,r3,_auc, _loss,_=sess.run([embedding,a_list,a_list_soft,auc,loss,train_op], feed_dict={user: [z],\n",
    "                                        i: [ta], j: [b], xf: new_yes , l_id:new_sample, l_id_len:[len(new_sample)],r:new_r_3,\n",
    "                                        image_i:image_1,image_j:image_2})\n",
    "                \n",
    "                #print(XUIJ)\n",
    "                #print('loss=',_loss)\n",
    "                #print('auc=',_auc)\n",
    "                \n",
    "                #print('after softmax:',r3)\n",
    "                #print('before softmax:',_a_list)\n",
    "                #print('embedding:',_embedding)\n",
    "                #print('---------------------------------------------------')\n",
    "                a_list_history.append(_a_list)\n",
    "                alpha_history.append(r3)\n",
    "                train_auc += _auc\n",
    "                total_loss += _loss\n",
    "                length += 1\n",
    "            #now1+=1\n",
    "        \n",
    "        np.save(LATENT_FOLDER + str(q) + '_' + str(z),_embedding)\n",
    "    \n",
    "    #print('mine:',xuij_auc/136)   \n",
    "    #print('a_list_soft:',r3)\n",
    "    print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "    print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "    \n",
    "    loss_acc_list.append([total_loss/length, train_auc/length, time.time()-t0])\n",
    "    \n",
    "    print('\\tCurrent time:', time.ctime())\n",
    "    print('==================================================')\n",
    "    \n",
    "print('Total cost time:',time.time()-t0)\n",
    "\n",
    "print('End time:', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss= [[0.08499577]]\n",
      "acc= 0.9721809383910827\n",
      "time= 2515.162266254425\n",
      "Iteration: 1\n",
      "loss= [[0.03215997]]\n",
      "acc= 0.9897088049771019\n",
      "time= 5034.868119716644\n",
      "Iteration: 2\n",
      "loss= [[0.01103309]]\n",
      "acc= 0.9965739220599672\n",
      "time= 7552.309334039688\n",
      "Iteration: 3\n",
      "loss= [[0.00624372]]\n",
      "acc= 0.9981875918085198\n",
      "time= 10073.605615139008\n",
      "Iteration: 4\n",
      "loss= [[0.00428414]]\n",
      "acc= 0.998714680722371\n",
      "time= 12599.873846292496\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_acc_list)):\n",
    "    print('Iteration:',i)\n",
    "    print('loss=',loss_acc_list[i][0])\n",
    "    print('acc=',loss_acc_list[i][1])\n",
    "#     print('time=',loss_acc_list[i][2])\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U, Y, A, A1, Au, Ay, Aa, Av, E, B = sess.run([user_latent, item_latent, aux_item, \n",
    "                                              W1, Wu, Wy, Wa, Wv, embedding, Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent shape:  (1582, 128)\n",
      "photo latent shape:  (165, 128)\n",
      "Auxilary latent shape:  (165, 128)\n",
      "W1 weight shape:  (1582, 128)\n",
      "Wu weight shape: (128, 128)\n",
      "Wy weight shape: (165, 128, 128)\n",
      "Wa weight shape: (128, 128)\n",
      "Wv weight shape: (128, 4876)\n",
      "Embedding shape: (200, 4876)\n",
      "Beta shape: (1582, 200)\n"
     ]
    }
   ],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('W1 weight shape: ',A1.shape)\n",
    "print('Wu weight shape:',Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./weight/' + SAVE_NAME + '.npz', \n",
    "         U=U, Y=Y, A=A, A1=A1, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, E=E, B=B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1255\n",
      "alpha:         [6.77531498e-44 3.59987046e-44 1.31157949e-20 1.31039733e-20\n",
      " 1.32716208e-20 1.37928180e-20 5.87008367e-20 1.11279801e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "1 1213\n",
      "alpha:         [-1.81889880e-19  7.10642767e-44 -1.01442704e-19 -7.98198317e-20\n",
      " -2.77612902e-20 -1.52539696e-19  7.02745936e-45 -1.47386586e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "2 12\n",
      "alpha:         [-3.64276364e-27 -2.10453019e-26 -3.77136739e-26 -1.08946081e-27\n",
      " -4.26036027e-26  1.38490942e-26  3.67114903e-26 -9.92332858e-27\n",
      "  8.45109301e-28  2.40358653e-28 -6.36150171e-51]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "3 1405\n",
      "alpha:         [ 2.06542449e-20 -1.67202780e-21 -2.05337275e-20  4.15318676e-20\n",
      "  1.44305580e-19  7.35671529e-22 -1.64865824e-20  1.09938747e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "4 1325\n",
      "alpha:         [-1.71565049e-26 -3.46088391e-27  1.93363008e-27 -4.98175136e-28\n",
      "  5.74406581e-27 -2.24179846e-34  7.24712749e-51 -9.20682813e-27\n",
      " -7.74544459e-27  2.54022809e-26  4.45164032e-51]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "5 287\n",
      "alpha:         [-2.36129407e-21 -1.42664619e-20  2.58346606e-21 -2.48023321e-20\n",
      " -4.19488508e-21 -5.22899380e-20 -4.81737737e-28 -5.30598039e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "6 439\n",
      "alpha:         [ 1.78166804e-33 -9.62851786e-34  1.65083764e-34  1.35075129e-34\n",
      "  4.70150318e-34  1.78336911e-34  1.34119424e-33  3.02888656e-33\n",
      "  6.39283582e-34 -4.52420671e-34  8.17304502e-34  4.75925899e-35\n",
      " -6.41821982e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "7 1430\n",
      "alpha:         [-1.95640466e-20 -3.06259030e-32 -6.51231477e-28  8.40952470e-45\n",
      " -5.92022624e-21  7.48139782e-20  8.30301411e-20  3.85896428e-44]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "8 1300\n",
      "alpha:         [-5.14142971e-50 -4.16385135e-50 -5.45707972e-27 -1.01828508e-27\n",
      " -2.72493317e-26 -5.47594998e-27 -3.47501360e-26 -2.13313947e-26\n",
      " -1.29172834e-25 -3.73283579e-50 -7.66808107e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "9 274\n",
      "alpha:         [-1.36092314e-19 -2.63627190e-20 -5.59778784e-20 -1.26652644e-19\n",
      " -4.33108373e-20 -2.45431167e-19 -1.28610470e-19 -1.37084391e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "10 71\n",
      "alpha:         [ 5.69994844e-22  2.26978320e-22  3.01047726e-21  1.16390163e-22\n",
      "  4.47400103e-23  1.76785350e-21  3.27579566e-22  4.60896796e-22\n",
      " -2.27768679e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "11 698\n",
      "alpha:         [-2.47152359e-27  1.93936392e-50  1.11786860e-50 -2.47832379e-27\n",
      "  2.67773223e-26  6.43187100e-27  1.65206921e-29  3.07130271e-26\n",
      "  4.88626902e-51 -2.90808004e-26  8.23805502e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "12 182\n",
      "alpha:         [ 6.94292579e-20  2.03638410e-20  5.59222864e-20  4.74178914e-20\n",
      "  7.05164481e-20 -4.38179268e-21  1.25326198e-19  5.93212050e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "13 284\n",
      "alpha:         [-6.54281200e-20  1.99278454e-20  6.75158697e-23 -1.06310046e-20\n",
      " -1.64588149e-44  4.33347351e-20  3.13319900e-21  1.49635552e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "14 770\n",
      "alpha:         [-5.72604942e-36 -1.89687868e-35 -1.77142824e-36 -9.26743621e-37\n",
      "  8.88597520e-35 -1.64006708e-34 -2.65836358e-59 -4.18949732e-35\n",
      " -4.26905668e-35 -1.69155216e-59 -2.48202258e-35  1.61759267e-35\n",
      " -2.11698391e-58 -1.23036398e-34 -1.45747704e-34]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "15 265\n",
      "alpha:         [-1.20137334e-29 -9.99547089e-30  2.56814643e-29  8.41805919e-46\n",
      " -4.49058033e-37 -1.17999217e-30 -3.75652286e-53 -1.63224202e-29\n",
      " -8.58393621e-30 -7.04896104e-53 -8.37051275e-30 -9.54915962e-30]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "16 1439\n",
      "alpha:         [-3.18105001e-24 -2.72886288e-32 -9.66305606e-25 -4.15036787e-24\n",
      " -6.80569351e-24  2.51942499e-24 -4.90881868e-48 -4.41182121e-43\n",
      " -1.08422785e-24 -3.07332330e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "17 1204\n",
      "alpha:         [-1.29341929e-21 -1.07909939e-21 -1.77523540e-22 -2.82756473e-22\n",
      " -8.18002367e-23 -9.41318046e-23 -2.19731072e-30  2.34208037e-22\n",
      " -1.21681221e-21]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "18 1313\n",
      "alpha:         [-7.99625927e-22  7.00890881e-20  3.10493737e-19  2.73260609e-20\n",
      "  7.76660186e-20  2.46213742e-19  1.27695147e-44  1.81675980e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "19 1279\n",
      "alpha:         [-1.01437463e-25 -1.20763002e-26  4.00473527e-27 -3.57740132e-26\n",
      " -5.22134672e-26 -3.64870270e-26 -2.91706346e-26 -1.20284306e-26\n",
      " -2.74729022e-27 -2.16766679e-26 -1.97882359e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "20 508\n",
      "alpha:         [ 1.39832846e-21 -7.54129716e-22  6.49422188e-22  7.68237541e-22\n",
      "  1.06967992e-21  2.25004349e-22  5.87559367e-22  4.01947043e-23\n",
      "  2.72920514e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "21 254\n",
      "alpha:         [-1.53738732e-21 -4.04291098e-22  4.30416864e-22 -6.41094527e-22\n",
      " -5.58008485e-22 -1.60459312e-38 -6.26740161e-22  6.61154891e-23\n",
      "  1.15206539e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "22 1262\n",
      "alpha:         [ 6.01234968e-25 -4.61092620e-25  6.77342710e-25  2.46912408e-25\n",
      "  1.03414763e-24 -2.08100383e-27  9.32171315e-24 -9.19943972e-25\n",
      "  3.82503956e-26  9.18313083e-25]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "23 55\n",
      "alpha:         [-7.00998126e-24  4.28057317e-25  1.13747641e-24 -7.10233469e-25\n",
      " -2.16282255e-24 -7.23465345e-48 -6.10101614e-48 -1.38776350e-23\n",
      " -6.74525269e-24  1.77649198e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "24 1458\n",
      "alpha:         [ 1.67071575e-36  2.68137359e-35 -6.90484347e-35  1.39036648e-36\n",
      " -5.96062008e-43 -9.24803368e-36 -2.90825254e-35 -6.36870303e-36\n",
      " -1.05853159e-34 -6.27791588e-36 -1.22994533e-35 -3.09184018e-35\n",
      "  8.66334123e-36 -2.13687591e-35 -1.20997863e-35 -1.61950648e-34\n",
      "  2.82436953e-35 -3.32955324e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "25 869\n",
      "alpha:         [-1.91857449e-36 -3.05882415e-24  9.18445167e-25  4.41115900e-25\n",
      " -4.74598724e-25  1.75853620e-24  2.27902293e-24  9.21638914e-25\n",
      " -2.69501146e-24 -4.76869940e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "26 1571\n",
      "alpha:         [ 2.77585459e-33 -1.43982406e-57 -4.21764207e-34 -1.16666537e-57\n",
      " -7.55805677e-35  9.85491326e-35 -1.68399533e-33  1.59411333e-33\n",
      " -4.35011836e-34  2.00410941e-36 -1.18331947e-35 -3.53649867e-41\n",
      " -7.08756641e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "27 1132\n",
      "alpha:         [-3.88247005e-36  2.15987832e-35 -1.04097164e-36 -1.57872644e-35\n",
      " -7.75361412e-36  2.37506386e-37 -7.44003674e-36 -1.23266435e-35\n",
      "  3.84247848e-36  5.61073131e-35  4.65228967e-53  3.38211999e-35\n",
      " -1.44117823e-36 -3.92384031e-59 -1.33874323e-59  1.08102985e-34\n",
      " -1.70727865e-35 -3.73198188e-38 -1.08620527e-36 -2.66225768e-59]\n",
      "softmax alpha: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "==================================================\n",
      "28 161\n",
      "alpha:         [ 1.47590775e-20 -5.19298720e-20 -5.17573051e-20 -3.14773807e-21\n",
      " -2.57058619e-20 -4.77850535e-20  2.14107396e-21  8.11568293e-33]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "29 404\n",
      "alpha:         [-2.10619337e-24 -4.98512643e-24 -1.22504497e-26 -7.04204071e-48\n",
      " -7.74005359e-25  2.62464800e-25 -6.28607073e-25 -2.48902754e-24\n",
      " -1.97015453e-24  4.04002097e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "30 98\n",
      "alpha:         [-1.23893987e-19  6.65965101e-21 -1.68353514e-32 -2.75282540e-19\n",
      "  1.73658015e-21 -3.36014804e-20 -9.81693220e-44  3.92629917e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "31 553\n",
      "alpha:         [6.49497488e-22 5.37902514e-22 1.47365187e-21 8.98580496e-23\n",
      " 1.95747354e-30 2.82096519e-38 1.34556270e-45 7.45333571e-22\n",
      " 1.73968623e-21]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "32 1424\n",
      "alpha:         [ 6.87889029e-35  1.35952502e-34  1.51099340e-58  1.06226171e-34\n",
      "  1.64002030e-35 -3.29139065e-35  1.75469262e-34  2.33492578e-35\n",
      "  1.68775864e-34  3.21600745e-35  1.28915462e-34  1.32688200e-35\n",
      " -3.23628639e-35  4.11736250e-34  1.82568805e-36]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "33 221\n",
      "alpha:         [ 2.86085099e-34 -4.52410452e-35 -1.61610819e-33 -1.49252965e-34\n",
      "  6.56896125e-34 -1.98085461e-33 -5.10176837e-33 -2.43280162e-34\n",
      " -1.15669563e-33 -1.53018047e-33 -6.38241753e-34 -9.51478708e-34\n",
      " -3.37556374e-33 -2.30059179e-41]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "34 1006\n",
      "alpha:         [-1.03986557e-20 -6.11227781e-20 -3.60787139e-19 -1.88066827e-21\n",
      " -4.60793705e-44  5.93482219e-23  8.34427145e-20 -1.11859015e-43]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "35 341\n",
      "alpha:         [-1.38687720e-35 -2.54116621e-35  2.97539328e-36  2.59817170e-35\n",
      " -6.90223735e-36 -2.42616124e-35 -6.29848956e-35 -5.52790883e-35\n",
      " -1.03535661e-43 -1.96427705e-35 -4.14334854e-35 -1.10736441e-34\n",
      " -4.63252556e-35 -2.92374316e-35 -2.66775437e-37 -3.01533639e-59\n",
      " -3.20022520e-37 -8.73667525e-36 -1.84323655e-35 -1.20008454e-36\n",
      " -1.62775182e-35 -7.99537399e-36 -2.46963696e-35  1.94311281e-37\n",
      " -6.91301925e-35  8.80468835e-36 -2.16129933e-35 -4.23432757e-35\n",
      " -3.21635561e-35 -2.89820654e-54  7.21273817e-36 -1.67647893e-35\n",
      "  1.70859000e-35]\n",
      "softmax alpha: [0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303 0.03030303\n",
      " 0.03030303 0.03030303 0.03030303]\n",
      "==================================================\n",
      "36 126\n",
      "alpha:         [-1.29957201e-23 -1.41100026e-23 -9.92854110e-24 -9.90810601e-24\n",
      " -2.32397769e-25 -1.15207697e-23 -3.33031690e-24 -2.95498121e-24\n",
      " -1.91151521e-24 -3.96943398e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "37 928\n",
      "alpha:         [-2.58854274e-20 -7.59863386e-20  1.68564069e-20  6.60488599e-20\n",
      "  4.94879198e-44  2.15212871e-20 -1.88525114e-20 -2.54113345e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "38 1339\n",
      "alpha:         [-4.56627625e-35 -1.65844552e-34 -7.50491364e-60  2.25956633e-35\n",
      "  3.03021955e-35  1.15535708e-35 -1.80554051e-34  2.37609281e-35\n",
      " -2.04201956e-36 -9.37281242e-36 -2.92062968e-35  1.17326911e-35\n",
      " -1.40580216e-35 -3.94388554e-35 -2.59383617e-35 -4.03912807e-36\n",
      " -2.65724806e-35  5.33764823e-35  7.50977605e-35 -2.19202414e-35\n",
      " -2.66153907e-36  6.00581509e-35 -3.34417836e-59 -8.80259635e-36]\n",
      "softmax alpha: [0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667]\n",
      "==================================================\n",
      "39 889\n",
      "alpha:         [-1.68441385e-57  1.81775614e-33  2.28843817e-58  2.54229611e-33\n",
      "  6.71503711e-34 -7.56393151e-33  3.25249763e-33 -8.26778277e-34\n",
      "  1.81410390e-42  1.67742285e-34  2.91381564e-34  8.58507629e-34\n",
      " -4.92266619e-34  8.44962712e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "40 498\n",
      "alpha:         [-9.46240595e-59 -4.96644663e-35 -4.40743602e-36 -1.60872229e-35\n",
      " -1.02306705e-34 -5.68513909e-35 -5.08784535e-36 -3.75924469e-35\n",
      "  7.60567809e-36 -7.54565306e-35 -3.36351927e-35 -9.78732364e-36\n",
      " -9.34215604e-35 -2.37469278e-35 -1.79093595e-34 -1.90252021e-35\n",
      " -1.09786502e-58 -7.67841778e-59 -5.11849739e-35]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "41 1437\n",
      "alpha:         [-2.06328764e-20 -7.35078473e-22 -6.06911807e-20  3.83515658e-20\n",
      " -2.82967780e-20  8.03047623e-21  2.89968231e-21 -4.77463847e-44]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "42 1122\n",
      "alpha:         [-2.96135267e-24 -1.34663064e-25 -4.79479166e-49  6.36037681e-24\n",
      " -6.28020881e-48  1.52755508e-24 -1.58644339e-24  2.31028529e-24\n",
      " -9.77831594e-25  2.80410217e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "43 749\n",
      "alpha:         [-1.35705828e-34 -1.17310295e-35  8.21674191e-36 -3.91349209e-36\n",
      " -5.64178361e-35 -8.49058391e-35 -1.90782240e-36  1.50128196e-59\n",
      " -2.76383059e-47  6.40255663e-36 -6.59076832e-35 -8.40614080e-35\n",
      " -1.47164775e-35 -6.56602319e-35 -1.08594982e-36  3.35129287e-59\n",
      "  1.61490226e-36 -1.22171709e-35  2.29249999e-36 -1.61152472e-35\n",
      " -7.90480722e-36 -3.87752009e-35 -2.23638858e-35 -1.90677805e-35\n",
      "  4.84225087e-36  6.04072306e-35 -1.01662167e-34 -6.20937428e-35\n",
      " -8.96737491e-35]\n",
      "softmax alpha: [0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276]\n",
      "==================================================\n",
      "44 23\n",
      "alpha:         [-6.40022674e-59 -6.60528066e-35  3.03011267e-35  5.73988108e-37\n",
      " -3.75001839e-35 -1.52317684e-35 -4.61345596e-59  7.47729354e-36\n",
      "  3.06085204e-36 -4.96670910e-35  5.69141930e-35 -2.93819253e-35\n",
      " -2.28396057e-35 -4.88962112e-43 -3.40285700e-35 -2.86291107e-35\n",
      " -8.73098998e-59 -7.61258699e-36  5.75375914e-35]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "45 957\n",
      "alpha:         [ 8.35151235e-34 -2.40774333e-33 -1.14413679e-33 -6.37682391e-35\n",
      " -6.40495638e-58  7.13021499e-33 -8.27520424e-34  3.35918459e-35\n",
      " -6.62214943e-33 -1.17711036e-33 -2.15892954e-33  3.50179122e-36\n",
      "  1.33801594e-33 -1.85851345e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "46 327\n",
      "alpha:         [-7.78098152e-35  5.33412076e-59 -2.07584383e-36  2.37121986e-35\n",
      " -7.15839357e-35  5.48404144e-59 -6.41805272e-35 -2.93290194e-35\n",
      "  3.60604747e-35 -5.47164089e-36  1.77738454e-35  2.00324726e-36\n",
      " -1.98376709e-43 -4.10568097e-36 -4.49269871e-35 -5.20140184e-36\n",
      " -5.49340715e-35 -4.82941823e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "47 1144\n",
      "alpha:         [-1.55024589e-34 -1.96676868e-37  9.06915910e-37 -4.57031927e-35\n",
      " -6.46674282e-59 -2.73743751e-35  1.81324697e-35 -8.02960440e-37\n",
      " -6.50751739e-60  3.18716040e-35  2.59504014e-35 -8.26276427e-37\n",
      "  1.52466485e-35 -2.12290256e-59  7.28676668e-35  6.05439962e-37\n",
      " -1.30985351e-36 -6.47147696e-59 -5.62793101e-36  2.47780828e-37\n",
      " -1.56011353e-35  1.16776005e-36]\n",
      "softmax alpha: [0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455]\n",
      "==================================================\n",
      "48 174\n",
      "alpha:         [1.28916180e-23 1.13997978e-21 2.04101419e-23 9.35868985e-24\n",
      " 7.85773779e-23 2.72278397e-46 1.08280663e-21 6.76416616e-24\n",
      " 1.63730082e-21]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "49 829\n",
      "alpha:         [3.48560283e-22 1.76733638e-21 2.92830388e-22 9.19486586e-46\n",
      " 1.48976548e-45 1.71589066e-22 6.18183651e-23 9.75330158e-23\n",
      " 7.12039497e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "50 403\n",
      "alpha:         [-8.56531695e-20 -1.62866697e-19 -3.04881455e-20 -1.12679506e-19\n",
      " -7.84461549e-20 -4.18136302e-20  9.18791696e-23  1.81933264e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "51 933\n",
      "alpha:         [-1.47635914e-35 -1.86114259e-36  1.14362354e-35 -1.50475460e-59\n",
      "  4.37544530e-35 -1.14267336e-35 -6.18167353e-35 -6.38803971e-35\n",
      " -4.02422799e-36  6.13371153e-35 -7.73266491e-35 -7.73900648e-35\n",
      " -3.95253754e-43 -3.71479576e-59 -2.11897460e-59 -7.16631333e-36\n",
      "  1.62822995e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "52 1334\n",
      "alpha:         [ 4.40255003e-24  1.13372795e-25 -5.65936620e-25  5.25805405e-25\n",
      " -1.06695430e-24 -2.48854990e-24  2.23387763e-24  3.22414063e-32\n",
      "  1.90875516e-48  6.56753818e-26]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "53 1214\n",
      "alpha:         [ 6.33917464e-36 -7.31038574e-38  1.50692045e-59  3.83201142e-35\n",
      "  2.20448569e-37 -4.85902628e-60  2.96254422e-36 -6.18188324e-37\n",
      "  1.96205837e-34 -9.53996714e-52 -1.43311009e-36  7.64666765e-36\n",
      "  5.04652106e-44  2.18446029e-35 -7.60121880e-36  6.11555112e-36\n",
      " -2.91898702e-59  1.13503716e-34  5.09814832e-35  5.58221916e-36\n",
      " -9.04312338e-35  9.99845348e-36 -2.10603771e-59]\n",
      "softmax alpha: [0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
      " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
      " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
      " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826]\n",
      "==================================================\n",
      "54 361\n",
      "alpha:         [ 2.60559700e-27 -1.50076788e-26  1.44810939e-28  7.23439081e-51\n",
      "  8.82844571e-28 -3.16595559e-27 -1.43438895e-26  2.39371263e-27\n",
      " -4.41300143e-28  2.31903128e-27 -5.08866924e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "55 746\n",
      "alpha:         [ 1.87892918e-46 -3.41290413e-22  1.65184460e-21 -4.23103850e-22\n",
      "  1.20785319e-22 -8.26510577e-23  7.88327075e-23 -6.30491046e-22\n",
      " -2.90015815e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "56 920\n",
      "alpha:         [-3.06721993e-26 -1.82068687e-26 -4.01670936e-26 -3.61799767e-26\n",
      " -5.78143780e-27 -2.59242978e-51 -1.32115746e-26  1.31047436e-27\n",
      "  8.54411848e-27 -3.74252614e-27 -1.73757776e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "57 529\n",
      "alpha:         [-1.34629134e-34 -1.67544032e-34  6.41258520e-34 -1.32631403e-33\n",
      " -1.18308391e-35  7.31835246e-34 -9.59343683e-34 -1.15905454e-33\n",
      "  4.41005505e-35 -4.44624609e-34 -1.57034359e-34 -1.07850278e-33\n",
      " -1.28380419e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "58 1390\n",
      "alpha:         [-2.18921737e-46 -1.22400701e-21 -2.00620199e-24 -5.59718452e-38\n",
      " -5.97605290e-46 -6.16296472e-22 -4.12641361e-22  1.99506017e-22\n",
      " -4.73298890e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "59 620\n",
      "alpha:         [-9.47871269e-20 -1.37103229e-20  3.83931521e-20  7.60958970e-22\n",
      "  4.93518026e-21 -6.78704127e-29  2.66400841e-20 -4.10061619e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "60 1102\n",
      "alpha:         [-2.84491094e-33 -1.65728822e-34  4.82550131e-33  1.19308835e-33\n",
      " -1.87371124e-58 -1.14821083e-33 -3.47320889e-34  1.40794199e-33\n",
      "  3.02234830e-33 -1.20048456e-33 -9.50481882e-35  1.90085663e-53\n",
      " -2.52080922e-33 -1.46215006e-33]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "61 755\n",
      "alpha:         [-1.16468201e-36 -1.37931409e-20 -8.37070521e-20 -3.74152372e-20\n",
      " -9.28007358e-20  9.18264299e-21 -3.71952247e-20 -2.76888779e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "62 568\n",
      "alpha:         [ 2.37808647e-36 -4.53593373e-36  2.24613232e-59  3.55102366e-35\n",
      "  1.56192480e-36  3.85174581e-35  1.08986998e-34  8.52935346e-55\n",
      " -6.27815748e-36  1.16171353e-35 -2.18462032e-37  8.74331364e-35\n",
      "  8.09127351e-37 -1.59719261e-35  2.17518145e-36 -6.56433882e-35\n",
      "  2.57284671e-35  3.83619622e-35  3.77288747e-35  2.77664850e-35]\n",
      "softmax alpha: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "==================================================\n",
      "63 713\n",
      "alpha:         [-1.00985854e-24 -1.34883542e-24 -3.72118059e-24 -6.57522919e-25\n",
      " -3.13639783e-24 -6.15077653e-26 -1.89092006e-24 -1.48977047e-24\n",
      " -1.73069206e-24 -7.12523992e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "64 313\n",
      "alpha:         [-4.10734223e-22  1.21037409e-22 -1.77609381e-46 -8.03094898e-22\n",
      "  7.05767579e-23 -1.49278360e-21  4.46676976e-22  2.49416621e-22\n",
      "  3.63359838e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "65 1119\n",
      "alpha:         [-1.05158463e-45  1.50162234e-22 -1.01092701e-21 -1.33462575e-45\n",
      " -2.49038261e-22  1.31066083e-24 -1.12930912e-45 -1.26483717e-21\n",
      " -1.57440460e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "66 800\n",
      "alpha:         [ 1.85777358e-36 -2.32948099e-34  8.46096163e-34 -1.29121063e-33\n",
      "  9.69875016e-34  1.61433796e-33  6.58500499e-34 -9.62400833e-34\n",
      "  5.02497463e-34  9.24475810e-34  1.43447063e-34  7.45644138e-34\n",
      " -1.70326709e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "67 1423\n",
      "alpha:         [ 8.66131931e-35  4.23962272e-35 -2.87432398e-35  1.33548465e-36\n",
      " -9.46594857e-36  2.84334765e-35  2.17830103e-35  7.42381164e-59\n",
      "  2.83030738e-35  4.26512410e-35  5.72916748e-35  1.07465687e-35\n",
      " -7.02762290e-38  1.71789084e-35  1.00718478e-58  4.83773545e-35\n",
      "  3.38977704e-37  7.89322956e-59  1.41047044e-34  8.52131274e-36\n",
      "  2.98406396e-35  1.73319547e-48  1.03717837e-34  1.57096775e-35\n",
      "  1.27485530e-35  2.07734270e-35  1.09019569e-34  5.69623982e-35\n",
      "  5.07684039e-35  2.85478550e-35  3.65409305e-36  6.44524545e-36\n",
      "  2.97632953e-35  1.05612785e-34  3.28719847e-35  1.49101422e-34\n",
      "  4.62939541e-43  5.53303967e-35]\n",
      "softmax alpha: [0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "==================================================\n",
      "68 1514\n",
      "alpha:         [-1.84738338e-34  5.05247425e-35 -1.67253382e-34 -8.22618052e-34\n",
      "  1.51680690e-34 -1.04367044e-57  1.80305070e-33 -6.60600773e-35\n",
      " -2.80648217e-34  1.61701117e-33 -2.29237045e-33 -1.57595764e-33\n",
      " -1.97977009e-33]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "69 764\n",
      "alpha:         [-1.02092993e-22 -5.32595299e-20 -8.01507003e-22 -7.74862109e-30\n",
      "  2.48701516e-39  4.91208569e-21 -3.46661544e-20 -8.52435933e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "70 1365\n",
      "alpha:         [ 1.11612066e-48  9.57731194e-25  6.48789198e-24  9.28215312e-25\n",
      "  6.11029210e-24 -8.58842750e-49  5.99738779e-48  8.11217517e-24\n",
      " -6.98641528e-25  2.38963070e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "71 1011\n",
      "alpha:         [ 2.10448596e-22 -9.31396573e-23 -5.13549658e-22 -1.20115553e-37\n",
      " -4.88037367e-22 -3.80025019e-22  8.23814924e-24  4.06786266e-22\n",
      "  3.28215922e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "72 836\n",
      "alpha:         [1.68210834e-21 1.74786906e-20 4.27832483e-20 5.23619021e-44\n",
      " 7.15457135e-20 5.66890513e-22 4.94925813e-20 4.92699356e-44]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "73 131\n",
      "alpha:         [-7.70797266e-34 -1.29826177e-33  1.22156534e-35  3.86315680e-33\n",
      "  8.20460505e-33 -1.67238235e-33  2.49589614e-34 -2.18917393e-41\n",
      " -3.07104134e-34 -1.08396275e-32  1.37805326e-33  1.18055946e-33\n",
      " -3.86108256e-34 -9.75891183e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "74 915\n",
      "alpha:         [ 8.57520310e-36  1.13729986e-35 -3.40213928e-36 -3.97374531e-35\n",
      " -2.20389156e-35 -3.17218454e-36 -5.20276433e-59 -1.94757416e-35\n",
      " -3.44876492e-35 -4.29356286e-36 -9.19622363e-35  9.48156492e-38\n",
      " -2.92312430e-35  2.03920764e-36 -5.00385098e-35 -4.77938227e-35\n",
      " -3.42543672e-35  2.68167054e-35 -5.74581404e-35 -1.60278918e-34\n",
      " -1.38626544e-35]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "75 1093\n",
      "alpha:         [-5.41444347e-40  4.57248539e-27  4.69871139e-51  2.96457642e-27\n",
      " -1.12348669e-26  3.80560911e-27  2.18155614e-26 -1.97380061e-26\n",
      "  6.52935106e-27 -2.37903573e-27  4.37352736e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "76 219\n",
      "alpha:         [-8.93112978e-22  4.90925666e-23  3.63408088e-22 -2.28094920e-22\n",
      "  8.12033521e-23  5.49826734e-22 -8.42998493e-23  3.24396169e-22\n",
      "  2.74127180e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "77 634\n",
      "alpha:         [-9.63233565e-21 -6.49822147e-21 -7.92973107e-21 -3.29593969e-20\n",
      " -1.82564988e-20 -2.22067477e-19 -4.71065198e-44  2.15050884e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "78 1378\n",
      "alpha:         [-3.66734156e-21  2.05107393e-21 -4.06731287e-44 -1.03478170e-19\n",
      " -1.66091559e-20 -1.11038399e-19 -9.15317129e-44  9.32405404e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "79 930\n",
      "alpha:         [-4.10148065e-20 -5.53584018e-20 -3.77208160e-22 -5.71226235e-44\n",
      " -1.45645395e-20 -3.48552976e-21 -1.45277039e-20 -1.35848305e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "80 473\n",
      "alpha:         [ 2.08761012e-26  4.61606751e-27  1.89889588e-28  3.06896078e-26\n",
      " -5.38395777e-29  4.55695700e-26  6.39454866e-27 -1.59147612e-27\n",
      "  3.66952252e-27 -1.99395782e-34  6.08621202e-51]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "81 194\n",
      "alpha:         [-1.98825371e-24  1.20577399e-24  1.94630193e-24  7.81551659e-24\n",
      " -9.98986307e-25 -1.18706919e-25  4.82877734e-24 -2.98116728e-24\n",
      " -1.03164017e-26 -6.97061809e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "82 349\n",
      "alpha:         [ 5.32853896e-44  2.08243147e-20  5.99806403e-21  1.35740140e-20\n",
      " -3.87531291e-20  1.70578528e-20 -7.33778097e-21  5.82571788e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "83 10\n",
      "alpha:         [-2.43886739e-26 -5.32032557e-27 -2.54326842e-28  1.93701243e-27\n",
      "  4.19235846e-27  1.90551683e-27 -1.23035541e-26  8.62398902e-27\n",
      " -1.29797804e-28 -4.18326775e-27  4.38100079e-39]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "84 688\n",
      "alpha:         [ 7.09271517e-58  9.18457856e-34 -2.68580411e-35  5.28997712e-33\n",
      "  1.32187051e-34  3.37056253e-34  1.90300542e-36  1.84035433e-33\n",
      "  5.59524598e-34  2.47160542e-33  1.97202853e-33  4.69216806e-33\n",
      "  1.04963824e-33]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "85 523\n",
      "alpha:         [-2.01783836e-20  2.60926024e-20  5.23160602e-33  6.70881963e-20\n",
      "  5.47267460e-20  9.41692840e-21  3.84247220e-20  3.74010655e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "86 519\n",
      "alpha:         [ 1.08184796e-20  7.75676462e-22  6.04773784e-20  1.04735185e-21\n",
      "  1.70855486e-19  1.24874302e-19 -1.75029371e-19 -1.08498840e-43]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "87 712\n",
      "alpha:         [ 2.16743722e-24  1.09439522e-23 -4.90555492e-24  3.31153664e-24\n",
      " -2.18662731e-24 -1.58480179e-25 -5.98868046e-24  1.17680425e-25\n",
      " -1.29385943e-24 -7.19614785e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "88 959\n",
      "alpha:         [ 1.31094645e-49 -1.45730711e-34  2.64456380e-34  2.17179084e-33\n",
      "  2.09611456e-33 -1.20046566e-33 -2.16134182e-34  9.83264306e-34\n",
      " -1.50069703e-42  9.90667106e-47  5.96895205e-34 -4.57005209e-35\n",
      "  1.18125094e-33]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "89 1375\n",
      "alpha:         [ 5.26689022e-20 -1.33274506e-47 -5.10068481e-22  8.67625735e-20\n",
      " -1.16978195e-19  3.25325713e-20  4.05860541e-20  4.44095829e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "90 805\n",
      "alpha:         [ 3.17969149e-35  2.90356319e-36 -8.17540254e-35  7.01231065e-35\n",
      "  5.10308752e-35  2.68589337e-35 -3.13812810e-36  3.61451112e-35\n",
      " -1.56034869e-35 -4.14188881e-35 -3.79807047e-36  2.38665251e-35\n",
      "  5.81354463e-37 -1.84814648e-41 -8.06767541e-35  1.25848465e-35\n",
      " -1.81555428e-36  4.15243627e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "91 1022\n",
      "alpha:         [ 1.34392805e-58  1.23843911e-34  8.50662239e-35  9.58933552e-36\n",
      " -6.86500836e-36  1.77198067e-34 -1.14320163e-35  7.31090944e-35\n",
      "  2.88139687e-34 -1.41421209e-36  3.97760505e-35 -4.11469391e-35\n",
      "  1.37893897e-34  5.94823538e-34  1.53770482e-34]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "92 282\n",
      "alpha:         [ 2.01676626e-22 -9.12308164e-20 -1.94470192e-19 -1.64359587e-20\n",
      "  5.56906680e-44 -4.71613342e-20 -9.20620486e-21 -6.91549751e-47]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "93 730\n",
      "alpha:         [ 9.47509818e-34  2.43529374e-57  1.01009893e-33  4.43354768e-34\n",
      "  1.09408082e-35  9.12276320e-35 -3.13652855e-34  2.86557662e-34\n",
      "  1.63282049e-34 -6.00665989e-34  2.18923183e-34  4.64361460e-35\n",
      "  7.20185304e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "94 103\n",
      "alpha:         [ 2.48681987e-26 -1.47942303e-27 -3.20886297e-27 -3.13204820e-27\n",
      " -2.65328668e-26  1.64946479e-45  2.59364354e-27 -8.54106198e-29\n",
      " -6.92955925e-27 -8.86027421e-27 -2.95588786e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "95 552\n",
      "alpha:         [-5.64558460e-21  1.14138147e-19 -7.85569032e-20  5.51633310e-20\n",
      " -6.68719802e-22 -9.39805431e-21  5.57220714e-21  8.01436806e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "96 1091\n",
      "alpha:         [-2.90647565e-20  1.36602882e-19 -6.14249088e-20 -4.50039502e-20\n",
      " -7.35798493e-20 -2.70840515e-20 -8.95903406e-20 -7.43389264e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "97 162\n",
      "alpha:         [-3.79315791e-20  7.76677586e-20  8.67799906e-20 -7.54081665e-20\n",
      "  3.76763251e-20  2.38283062e-20  1.54671374e-19 -9.62414667e-22]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "98 801\n",
      "alpha:         [ 5.38082980e-25 -3.23312927e-25  1.52048566e-23  1.02941227e-24\n",
      "  4.88154242e-25 -1.89572795e-24  1.04966520e-24  1.60112260e-24\n",
      " -1.42311907e-48  3.96850573e-25]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "99 1168\n",
      "alpha:         [-1.40909638e-34 -7.75259990e-59 -1.20364133e-35 -2.84323346e-34\n",
      " -4.56147670e-35 -2.05854916e-58 -3.12327606e-34 -2.59716577e-36\n",
      "  2.18293680e-36  2.32985597e-43 -1.09374111e-34  4.91189852e-37\n",
      " -1.09055740e-35  8.89724629e-35 -1.05978914e-34]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "100 848\n",
      "alpha:         [2.63960387e-34 2.73698046e-33 1.59780523e-35 4.02837092e-34\n",
      " 1.37232641e-34 4.75436321e-46 1.04229024e-53 1.66406160e-34\n",
      " 2.90734966e-58 2.88476713e-33 3.15634144e-33 5.94511300e-34\n",
      " 4.66258914e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "101 1392\n",
      "alpha:         [ 1.26927749e-35  8.53523520e-36  4.26931878e-38 -1.59034392e-59\n",
      "  1.06572782e-34  5.45086322e-35 -2.02381658e-34 -5.16305600e-59\n",
      "  8.09393894e-35  1.20416919e-34  1.02539485e-35  1.51788872e-35\n",
      "  1.40234324e-35  6.71943262e-36  5.70542950e-35  4.84507294e-52]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "102 1101\n",
      "alpha:         [ 1.49849921e-22  1.34667217e-22  3.67606041e-22 -2.77143638e-22\n",
      " -6.38972724e-22  9.92190442e-24  5.97458413e-23 -5.61158316e-22\n",
      " -1.13526257e-21]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "103 112\n",
      "alpha:         [-4.19410647e-26 -4.69434882e-28 -1.23055051e-26 -6.75462439e-26\n",
      " -1.81066774e-26 -6.89950870e-27 -2.50435165e-26 -2.23296690e-27\n",
      " -9.15102054e-28 -2.10252701e-26 -5.07276164e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "104 1161\n",
      "alpha:         [-3.47381353e-29 -4.71942800e-30 -1.22941663e-29 -1.09416787e-29\n",
      "  3.88915719e-29 -2.26521535e-29  9.07883722e-30  5.69700926e-29\n",
      "  3.08038075e-30 -4.36690399e-29 -8.83054555e-29 -4.03522425e-53]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "105 469\n",
      "alpha:         [-2.04626307e-34  8.86775788e-36  1.45388522e-35 -1.18053172e-34\n",
      "  1.53494014e-35 -1.49344675e-34  1.42675560e-42 -3.19723096e-59\n",
      " -3.17460334e-36 -3.46643149e-36  7.97408737e-36  6.18337120e-35\n",
      "  1.39851888e-34 -9.64286427e-35 -1.93831800e-34]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "106 1411\n",
      "alpha:         [ 4.62862148e-35 -8.51781747e-35 -2.42946632e-35  2.11146870e-36\n",
      "  3.91793824e-35  1.55043237e-35  2.37357673e-35  4.75069703e-38\n",
      "  8.95236366e-35 -9.68363117e-36  1.12021088e-35  8.70481910e-36\n",
      "  2.17633748e-36 -2.75139477e-35  5.86933193e-36  3.12144667e-35\n",
      " -1.65225780e-35 -1.43164033e-59  6.11336438e-35  1.45452376e-34\n",
      "  1.93657000e-35]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "107 747\n",
      "alpha:         [-2.52883919e-35 -1.56631224e-34 -5.00625529e-59 -2.19740498e-35\n",
      " -7.68509895e-35 -1.25633005e-34 -2.56684976e-35 -7.83589166e-36\n",
      " -8.20042328e-36 -1.21360933e-34 -1.45617038e-34 -9.41440371e-37\n",
      " -5.20798453e-35 -6.14907345e-59 -9.03392349e-37 -2.66182087e-35]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "108 225\n",
      "alpha:         [ 1.50450957e-33  1.79873885e-33 -1.73703278e-33  1.32169271e-33\n",
      "  4.89430294e-34 -1.79184553e-33  1.37612914e-33  2.90208450e-33\n",
      " -5.84563242e-34  9.05043555e-36  7.99122140e-33 -2.10635329e-35\n",
      " -3.19119164e-34  1.26731753e-33]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "109 1236\n",
      "alpha:         [-6.77836418e-22 -1.01134037e-29 -6.84296921e-22 -1.86044561e-45\n",
      " -1.22057765e-21 -4.22164339e-23 -3.99875882e-22 -8.74809167e-46\n",
      " -1.55313266e-21]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "110 738\n",
      "alpha:         [-2.51281076e-24 -1.53313824e-24 -3.01965715e-25  2.13215822e-25\n",
      " -7.65090750e-25  2.98265498e-48 -3.42158896e-24 -6.50531114e-26\n",
      " -5.95607211e-24 -3.29741121e-32]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "111 916\n",
      "alpha:         [-5.64704238e-23 -2.81250187e-22 -6.27157719e-22 -9.25707501e-23\n",
      " -2.42154764e-22 -5.35063664e-23 -7.65242984e-46 -6.27135075e-22\n",
      "  2.28602048e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "112 856\n",
      "alpha:         [ 1.02157755e-24 -7.75547571e-24  1.80991278e-26 -9.55346897e-25\n",
      "  2.13002753e-24  1.52895792e-25  1.39545479e-24  4.61429601e-24\n",
      "  4.26432665e-25  2.93197721e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "113 1256\n",
      "alpha:         [-1.00422303e-23 -7.51490852e-22  3.05117822e-22  1.12902553e-21\n",
      "  7.24862578e-22 -2.10843862e-21 -1.72985816e-22  2.45511973e-22\n",
      " -3.24281597e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "114 615\n",
      "alpha:         [ 6.56063870e-30 -4.28812268e-29  1.24802433e-28 -4.06709594e-29\n",
      " -2.65363946e-29  7.15022934e-30 -7.83415840e-29 -4.33246319e-30\n",
      "  4.56395114e-53 -5.01074181e-30 -4.91732548e-29 -2.34215758e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "115 802\n",
      "alpha:         [-5.20539485e-22 -2.40570517e-22 -2.93867971e-22 -6.59077259e-23\n",
      "  3.86859482e-23 -2.90256471e-22  2.99226474e-22 -2.24289378e-23\n",
      "  1.89709573e-24]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "116 54\n",
      "alpha:         [ 1.91896805e-26  4.28781661e-24  2.88587261e-48  6.86681385e-24\n",
      "  6.75009664e-25  1.43075924e-23  1.31855542e-24  5.46155703e-24\n",
      "  2.45993767e-24 -4.90065878e-25]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "117 979\n",
      "alpha:         [-1.70378239e-29  2.59807477e-29 -1.86808474e-30  4.54772247e-29\n",
      "  2.42320899e-29  4.37932674e-30  8.60955947e-29  2.91893426e-29\n",
      "  4.51752887e-29 -2.36498701e-53  5.27394475e-29 -4.44304880e-31]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "118 531\n",
      "alpha:         [ 1.57687698e-19  3.26808027e-20  4.62258518e-20  6.59851717e-20\n",
      "  4.54991627e-45  2.24649616e-20 -2.04782045e-21  1.59172090e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "119 1117\n",
      "alpha:         [ 3.72789183e-25 -4.69577207e-24 -5.34864906e-24 -2.40769990e-40\n",
      "  4.51526943e-26  7.21469885e-26  1.19020389e-25 -9.54682705e-26\n",
      " -1.93420474e-24 -7.60388210e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "120 752\n",
      "alpha:         [ 2.18693467e-19  6.49654204e-22  1.20122055e-19  3.00242064e-44\n",
      "  5.14835253e-20 -2.48578750e-20  5.88149225e-37  3.24921722e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "121 78\n",
      "alpha:         [-1.32359530e-35 -9.21884759e-36  2.51107835e-59 -2.61552668e-37\n",
      " -2.30767413e-34 -1.52461097e-35 -3.84762518e-35 -2.83189844e-35\n",
      " -1.09422155e-35  1.39539279e-35 -1.84343624e-35 -3.61415902e-36\n",
      "  4.12252957e-35  1.53379052e-35 -6.35052178e-37 -8.84820840e-35\n",
      " -4.33980981e-35 -7.40555854e-35 -6.32771779e-36 -2.09586088e-35\n",
      " -5.57044502e-35]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "122 1224\n",
      "alpha:         [ 3.20013289e-23 -2.20308163e-22  1.66864218e-22 -6.32340716e-23\n",
      " -2.25636590e-22 -5.70083433e-46 -3.17286938e-22  2.10392591e-22\n",
      " -5.90567088e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "123 339\n",
      "alpha:         [-3.29717639e-22  1.44339285e-20  6.32930025e-32  4.18337366e-20\n",
      "  1.49580301e-21  6.86920390e-20 -7.15462509e-21  3.79846648e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "124 983\n",
      "alpha:         [ 3.60950131e-24 -2.11551108e-24  4.36693233e-49  5.35670168e-24\n",
      "  1.46116125e-32  5.01777966e-24 -8.26619961e-25  3.18572766e-25\n",
      "  9.62208158e-49  1.83427966e-49]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "125 1113\n",
      "alpha:         [ 1.70219971e-19  5.13194575e-21 -3.77461857e-20 -1.97612550e-21\n",
      " -1.62590052e-19  1.72141096e-19  3.02353546e-20  5.84959850e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "126 694\n",
      "alpha:         [-4.41549085e-35  1.31121622e-37 -3.15627688e-35 -1.55554084e-35\n",
      "  4.41685540e-37 -3.58295417e-36 -2.79304005e-35  2.73428342e-35\n",
      " -1.34800598e-36 -2.47667301e-37  8.07830457e-36 -5.85149294e-36\n",
      "  1.24868531e-35 -1.22938927e-34  8.97600931e-36 -3.47326899e-35\n",
      "  7.38127980e-36  5.05926835e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "127 1299\n",
      "alpha:         [ 1.96220876e-20  1.65497320e-20  4.30901903e-20 -3.14101655e-20\n",
      "  4.89928481e-20  7.99417452e-44  4.19441835e-21 -5.36162968e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "128 1527\n",
      "alpha:         [-2.87784622e-21 -5.11181027e-47 -2.26644088e-22  1.01378049e-46\n",
      " -8.11175400e-22 -1.67863481e-38 -3.31306528e-46 -1.98268127e-21\n",
      " -2.24876706e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "129 720\n",
      "alpha:         [-3.33066311e-35 -4.16371782e-36 -8.54552855e-36  1.00286023e-34\n",
      " -9.23898868e-36 -3.13884987e-36  2.98667296e-37  4.76026680e-35\n",
      "  7.82160373e-35  3.25245989e-35  1.48314765e-35 -3.52187111e-35\n",
      " -5.42813410e-35  2.25789494e-35 -8.29384782e-36 -6.38348553e-36\n",
      " -2.08386666e-34  6.77313145e-35 -2.36052251e-35 -7.82809080e-36\n",
      " -9.33231477e-36 -4.11789264e-36  2.97724950e-36 -3.70262219e-35\n",
      " -5.46165938e-38 -2.38023256e-36 -7.54968234e-35  4.36655753e-35\n",
      " -2.08275993e-35  5.52285955e-35 -5.16188353e-35  6.83545780e-36\n",
      " -5.68115808e-36 -3.50074977e-35  6.75510798e-35 -2.32912103e-35\n",
      " -2.06673520e-35 -6.23458585e-35  1.99914293e-36 -3.30004874e-35\n",
      " -2.22477026e-35  1.37979595e-35 -2.54040612e-35  2.98880343e-35\n",
      " -1.34334255e-35  3.13772782e-35 -4.13796375e-35 -8.54289562e-36\n",
      "  4.65465437e-36 -6.78846692e-36 -3.18187878e-35  1.08768354e-34\n",
      "  4.41452598e-36  6.39860773e-37  5.02334448e-36 -2.09220076e-35\n",
      "  8.61292593e-36]\n",
      "softmax alpha: [0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386 0.01754386\n",
      " 0.01754386 0.01754386 0.01754386]\n",
      "==================================================\n",
      "130 513\n",
      "alpha:         [ 9.82258890e-35  9.36399251e-35  4.35350653e-35  7.84463655e-35\n",
      " -1.83028065e-42  8.47625395e-36 -1.08562690e-34  6.43815089e-35\n",
      " -4.71745837e-38  1.37669163e-35  6.90976300e-35 -2.37793548e-58\n",
      "  2.90869880e-34 -3.39960844e-34  1.60219957e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "131 86\n",
      "alpha:         [ 7.59183893e-22 -8.25294343e-21 -3.22206828e-20  4.52988424e-20\n",
      " -1.46574379e-20 -2.72071329e-21  7.51820671e-21 -1.44503905e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "132 179\n",
      "alpha:         [ 1.75915629e-20  1.08270264e-21  6.64579688e-20 -5.83996126e-21\n",
      "  1.28443247e-19  4.80726592e-20  7.70069441e-20 -6.88948868e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "133 1388\n",
      "alpha:         [ 1.73117786e-27  1.71017328e-26 -3.44736080e-28  9.78293831e-28\n",
      "  1.37000000e-43  4.85656253e-27  5.22050582e-27 -2.58953501e-26\n",
      "  4.41070230e-51  1.00820522e-26  2.72490917e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "134 901\n",
      "alpha:         [-2.79250385e-26 -3.76451992e-27  3.21916502e-28 -2.81029121e-27\n",
      " -6.58970821e-27 -3.06286730e-26 -3.19969336e-50 -1.46970140e-26\n",
      " -6.88266858e-26 -2.97258578e-50 -1.40229963e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "135 1139\n",
      "alpha:         [ 5.39459762e-20 -1.02435721e-21  2.31195190e-44  4.24015801e-20\n",
      " -4.36321178e-20 -7.79083028e-20  1.30864526e-20 -3.60818652e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "136 729\n",
      "alpha:         [-9.22965506e-25  1.70626271e-24 -7.73291831e-27  2.34877043e-24\n",
      "  4.29958532e-24  3.74987819e-24  9.80453938e-25  4.44269032e-48\n",
      "  1.45473596e-48  5.20018472e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "137 1576\n",
      "alpha:         [-7.16644478e-27 -2.59397105e-26 -8.64355738e-27 -1.08928179e-26\n",
      "  1.62786532e-26 -3.88358899e-51 -2.68617086e-27  2.86409523e-27\n",
      " -2.74363470e-40 -8.59516834e-27  3.29043140e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "138 695\n",
      "alpha:         [-6.99928835e-24 -1.22284988e-24 -4.56011717e-25 -8.37136343e-26\n",
      "  2.62911099e-26 -1.56590817e-36 -2.11822797e-24 -8.68663383e-26\n",
      " -5.02917175e-24 -4.12461768e-27]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "139 1531\n",
      "alpha:         [-8.42784932e-22 -2.97167950e-22  5.82046987e-23 -1.08180031e-22\n",
      " -5.01013970e-22 -8.86263998e-23 -9.81464465e-23 -2.60411790e-22\n",
      "  8.23687520e-25]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "140 961\n",
      "alpha:         [ 1.16965461e-44  1.80557521e-44  1.39420206e-21 -1.25052762e-36\n",
      " -4.35012785e-20 -2.20749064e-20 -2.50134115e-22  7.61710093e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "141 184\n",
      "alpha:         [-4.22916000e-24 -6.45062385e-22 -3.79591364e-22  3.66965196e-46\n",
      " -1.88842105e-22 -3.70010467e-22 -9.03679150e-23 -7.83609409e-22\n",
      " -2.70539039e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "142 610\n",
      "alpha:         [ 2.16685572e-32  6.82369889e-25 -3.76374830e-25 -1.43326890e-24\n",
      "  5.38468039e-48  2.23325905e-24  6.32146787e-24  2.49285254e-24\n",
      "  1.12878078e-23  3.12577646e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "143 1410\n",
      "alpha:         [ 5.20839425e-25 -6.06860916e-25 -5.51339715e-25 -1.58366726e-37\n",
      "  1.70356900e-23  1.32612942e-26 -1.09063865e-23 -1.23605758e-32\n",
      " -2.15476722e-24  1.12651222e-23]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "144 837\n",
      "alpha:         [-5.67703562e-33  2.74100548e-34  7.23058010e-34  3.46054650e-33\n",
      " -2.42891724e-33  1.67112751e-33 -1.41406559e-33 -1.88716621e-33\n",
      " -5.33515678e-34  1.37875645e-33  1.76909690e-33  2.22900117e-33\n",
      " -2.35021430e-33 -9.82757189e-35]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "145 1285\n",
      "alpha:         [-3.11674465e-44 -1.41229675e-19 -1.82262542e-20 -5.34568117e-20\n",
      " -1.28106480e-43 -1.51029974e-19 -1.93535468e-20 -6.80047185e-22]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "146 1065\n",
      "alpha:         [ 9.65408869e-22  7.99199306e-46  8.03493485e-22  1.01010427e-21\n",
      "  1.43333832e-21  2.89502482e-22  4.54327878e-22 -1.19223860e-23\n",
      "  2.61793037e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "147 530\n",
      "alpha:         [ 1.51330994e-36 -8.65826722e-52  1.79865178e-35 -3.52846658e-36\n",
      "  5.57383428e-35  3.51494455e-35  5.97011970e-35  5.22932632e-36\n",
      "  1.07024410e-34  1.35884919e-34  9.04082913e-35  1.60151877e-34\n",
      "  3.58059217e-35  5.11501373e-35  4.08532739e-35  9.13335258e-60]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "148 143\n",
      "alpha:         [-1.49884771e-35  1.80940415e-37  1.06302633e-35  3.02213520e-35\n",
      " -9.28363627e-36 -1.05901364e-35 -1.06691854e-35  5.03044317e-49\n",
      " -2.64654709e-47 -3.33276667e-43 -3.33188810e-36 -3.09717905e-35\n",
      " -1.06841192e-34 -8.24636263e-37 -1.38135416e-35 -5.15564767e-36\n",
      " -3.77855239e-35 -6.79464580e-37 -2.93545328e-35 -3.01670835e-35\n",
      "  3.79345687e-36 -1.38137478e-35 -4.75381776e-35 -3.47597560e-59\n",
      " -3.61230669e-35]\n",
      "softmax alpha: [0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04\n",
      " 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04]\n",
      "==================================================\n",
      "149 872\n",
      "alpha:         [-1.85126687e-24 -2.86890537e-24  2.98954722e-24 -9.13435558e-25\n",
      "  4.99030308e-33  7.60387453e-48  1.39347481e-24  1.58419139e-24\n",
      " -1.57084132e-24  2.47228551e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "'''\n",
    "\n",
    "#with Embedding\n",
    "result = np.zeros((usr_test_amount, movie_nb))\n",
    "RS = np.zeros((usr_test_amount, movie_nb))\n",
    "#test_idx --> Test 的 index\n",
    "\n",
    "test_yes_id = []\n",
    "\n",
    "for s in range(usr_test_amount):\n",
    "    print(s, test_idx[s])\n",
    "\n",
    "    yes = []\n",
    "    sample = random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #從training part 的positive feedback 取出YouTuber 當成Auxilary\n",
    "    #sample=result_yes_id[now]\n",
    "    test_yes_id.append(sample)\n",
    "    alpha = np.zeros([len(sample)])\n",
    "    \n",
    "    for a in range(len(sample)):\n",
    "        r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "        #print(test_idx[s])\n",
    "        #print(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0)))\n",
    "        alpha[a] = np.dot(A1[test_idx[s]],(relu(np.dot(Au,np.expand_dims(U[test_idx[s]],0).T) +\n",
    "                                                np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T) +\n",
    "                                                np.dot(Aa,np.expand_dims(A[sample[a]],0).T) +\n",
    "                                                np.dot(Av,np.expand_dims(all_npy[sample[a]],0).T)))) * r\n",
    "    mul = np.zeros((1,latent_dim))\n",
    "    \n",
    "    print(\"{:<15}{}\".format('alpha:', alpha))\n",
    "    print(\"{:<15}{}\".format('softmax alpha:', softmax(alpha)))\n",
    "    print('==================================================')\n",
    "    \n",
    "    for i in range(len(sample)):\n",
    "        mul += softmax(alpha)[i] * A[sample[i]] #attention alpha*Ai part \n",
    "    new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "    \n",
    "    for k in range(movie_nb):\n",
    "        result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "        RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "#print(RS[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#取出test的資料\n",
    "testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150*20\n",
    "target = np.zeros((usr_test_amount, movie_test_amount))\n",
    "#test_t 是true的\n",
    "#test_f 是false的\n",
    "        \n",
    "for z in range(usr_test_amount):\n",
    "    user_id = test_idx[z]\n",
    "    #positive target YouTuber list\n",
    "    youtube_t = test_t[z] \n",
    "    #not target YouTuber list\n",
    "    youtube_f = test_f[z]\n",
    "    \n",
    "    #前兩個放target的RS\n",
    "    for i in range(len(youtube_t)):\n",
    "        testRS[z][i] = RS[z][youtube_t[i]]\n",
    "        target[z][i] = 1\n",
    "        \n",
    "    for i in range(len(youtube_f)):\n",
    "        testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 16) (150, 16)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape, testRS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of positive data in testing: 300.0\n",
      "total testing data: 2400\n"
     ]
    }
   ],
   "source": [
    "sumtarget = 0\n",
    "for i in range(len(target)):\n",
    "    #print(np.sum(target[i]))\n",
    "    sumtarget += np.sum(target[i])\n",
    "print('num of positive data in testing:',sumtarget)\n",
    "print('total testing data:', usr_test_amount * movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),int(np.sum(target[i])))\n",
    "    count_0_all.append(top_0)\n",
    "    #print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = 0\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        #print(int(np.sum(target[i])))\n",
    "        total+=int(np.sum(target[i]))\n",
    "        if count_0_all[i][j] < int(np.sum(target[i])): #代表是0或1 (也就是target)\n",
    "            acc_0 += 1\n",
    "avg_acc = acc_0/100\n",
    "#print('avg_accuarcy for count_0:',avg_acc)\n",
    "#print(acc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),1) #取一個\n",
    "    count_0_all.append(top_0)\n",
    "    #print(np.sum(target[i]))\n",
    "    #print(top_0)\n",
    "    if top_0[0] < int(np.sum(target[i])):\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.17333333333333334 recall  0.08666666666666667\n",
      "F1_score: 0.11555555555555556\n"
     ]
    }
   ],
   "source": [
    "top1_prec = correct/len(testRS)\n",
    "top1_recall = correct/(sumtarget)\n",
    "print('prec ',top1_prec,'recall ',top1_recall)\n",
    "print('F1_score:',F1_score(top1_prec,top1_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_3 = topN(list(testRS[i]),3) #取一個\n",
    "    count_0_all.append(top_3)\n",
    "    #print(top_3)\n",
    "    for j in range(len(top_3)):\n",
    "        if top_3[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.10444444444444445 recall  0.15666666666666668\n",
      "F1_score: 0.12533333333333332\n"
     ]
    }
   ],
   "source": [
    "top3_prec = correct/(len(testRS)*3)\n",
    "top3_recall = correct/(sumtarget)\n",
    "print('prec ',top3_prec,'recall ',top3_recall)\n",
    "print('F1_score:',F1_score(top3_prec,top3_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_5 = topN(list(testRS[i]),5) #取一個\n",
    "    count_0_all.append(top_5)\n",
    "    #print(top_5)\n",
    "    for j in range(len(top_5)):\n",
    "        if top_5[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.07466666666666667 recall  0.18666666666666668\n",
      "F1_score: 0.10666666666666667\n"
     ]
    }
   ],
   "source": [
    "top5_prec = correct/(len(testRS)*5)\n",
    "top5_recall = correct/(sumtarget)\n",
    "print('prec ',top5_prec,'recall ',top5_recall)\n",
    "print('F1_score:',F1_score(top5_prec,top5_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "'''\n",
    "all_sort = []\n",
    "pre_matrix = np.zeros(shape=(usr_test_amount, movie_test_amount))\n",
    "for i in range(usr_test_amount):\n",
    "    top_5 = topN(list(testRS[i]),5) #取一個\n",
    "    #print(top_5)\n",
    "    all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "    for j in range(len(top_5)):\n",
    "        pre_matrix[i][top_5[j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 16) (150, 16)\n"
     ]
    }
   ],
   "source": [
    "print(pre_matrix.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG\n",
    "* https://daiwk.github.io/posts/nlp-ndcg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideal DCG，理想状况下的DCG。也就是说，相关性完全由高到低排序时算出的DCG：\n",
    "\n",
    "def IDCG(ideal_list): #ideal_list example = [1,1,1,1,1,0,0,....]\n",
    "    idcg = 0\n",
    "    for i in range(len(ideal_list)):\n",
    "        #print((2**true_list[i]-1),math.log2(i+2))\n",
    "        idcg += (2**ideal_list[i]-1)/math.log2(i+2)\n",
    "    #print('idcg',idcg)\n",
    "    return idcg\n",
    "\n",
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    #print('dcg',dcg)\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0954376594029295\n"
     ]
    }
   ],
   "source": [
    "total_ndcg = 0\n",
    "num_ndcg = 5\n",
    "for m in range(usr_test_amount):\n",
    "    idcg = IDCG([1]*num_ndcg)\n",
    "    pre_list = []\n",
    "    for s in all_sort[m][:num_ndcg]:\n",
    "        #print(s)\n",
    "        #print(target[m][s])\n",
    "        pre_list.append(target[m][s])\n",
    "    dcg = DCG(pre_list)\n",
    "    ndcg = dcg/idcg\n",
    "    #print(ndcg)\n",
    "    total_ndcg += ndcg\n",
    "avg_ndcg = total_ndcg/usr_test_amount\n",
    "print('NDCG:',avg_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.15500000000000003\n"
     ]
    }
   ],
   "source": [
    "total_prec = 0\n",
    "for u in range(usr_test_amount):\n",
    "    y_true = target[u]\n",
    "    y_scores = pre_matrix[u]\n",
    "    total_prec += average_precision_score(y_true, y_scores)\n",
    "    \n",
    "MAP = total_prec/usr_test_amount\n",
    "\n",
    "print('MAP:', MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
